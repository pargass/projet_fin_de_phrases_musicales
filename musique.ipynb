{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install MTCFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MTCFeatures\n",
    "from MTCFeatures import MTCFeatureLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTCFeatures.downloadData(dest='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = MTCFeatureLoader('MTC-FS-INST-2.0')\n",
    "seqs = fl.sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/MTCFeatures/MTCFeatureLoader.py:259\u001b[0m, in \u001b[0;36mMTCFeatureLoader.sequences\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m     opener \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m opener(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:399\u001b[0m, in \u001b[0;36mGzipFile.readline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_not_closed()\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:507\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompressed file ended before the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend-of-stream marker was reached\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_read_data( uncompress )\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(uncompress)\n",
      "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "phrase_data = []\n",
    "for ii, x in enumerate(seqs):\n",
    "    phrase_data.append({\n",
    "        'id': x['id'],\n",
    "        **x['features']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On commence par étudier les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13492, 62)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase = pd.DataFrame(phrase_data)\n",
    "df_phrase.shape # (13492, 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44,)\n",
      "(44,)\n",
      "(44,)\n",
      "['E4', 'C4', 'A3', 'G3', 'C4', 'C4', 'D4', 'C4', 'D4', 'E4', 'A3', 'G3', 'G3', 'F#3', 'G3', 'A3', 'F4', 'E4', 'D4', 'E4', 'D4', 'G3', 'D4', 'E4', 'D4', 'C4', 'A3', 'G3', 'E4', 'F4', 'E4', 'A3', 'E4', 'D4', 'G3', 'A3', 'G3', 'G3', 'F4', 'E4', 'D4', 'A3', 'B3', 'C4']\n",
      "[1.0, 0.5, 0.5, 0.75, 0.25, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.5]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True]\n",
      "4\n",
      "[1.0, 2.0, 2.5, 1.0, 1.75, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0]\n",
      "['0', '0', '1/2', '0', '3/4', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0']\n"
     ]
    }
   ],
   "source": [
    "# Chaque ligne du set représente une mélodie, représentée par des features.\n",
    "\n",
    "print(np.array(df_phrase['pitch'][0]).shape) # pitch représente la hauteur des notes\n",
    "print(np.array(df_phrase['duration'][0]).shape) # duration représente la durée des notes\n",
    "print(np.array(df_phrase['phrase_end'][0]).shape) # phrase_end dit si la note est la dernière de la phrase\n",
    "\n",
    "print(df_phrase['pitch'][0])\n",
    "print(df_phrase['duration'][0])\n",
    "print(df_phrase['phrase_end'][0])\n",
    "# On peut donc voir que chacun de ses 3 features est une liste de la même longueur que le nombre de notes dans la mélodie.\n",
    "\n",
    "# combien de fin de phrase dans le premier exemple ?\n",
    "\n",
    "print(np.sum(df_phrase['phrase_end'][0])) # 4\n",
    "\n",
    "# On pense découpere les séquences en sous séquences par notes avec un nombre fixe de notes par sous séquence. On pourra tester de diviser les séquences en sous séquences de nombre \n",
    "# fixe de note pour toutes les séquences ou bien de diviser les séquences par un nombre fixe pour toutes les séquences.\n",
    "\n",
    "print(df_phrase['beat'][0]) # beat représente le temps de la note dans la mesure\n",
    "\n",
    "# On peut aussi faire des sous séquences basées sur les mesures pour éviter de couper une mesure en deux.\n",
    "\n",
    "print(df_phrase['beat_fraction_str'][0]) # beat_fraction_str représente le temps de la note dans la mesure sous forme de fraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_phrase.describe()) # Pas utile pour les features qui sont des listes et trop long, ça sert à r ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_phrase.info() # 7302 sequences avec paroles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id <class 'str'>\n",
      "lyrics <class 'float'>\n",
      "noncontentword <class 'float'>\n",
      "wordend <class 'float'>\n",
      "phoneme <class 'float'>\n",
      "rhymes <class 'float'>\n",
      "rhymescontentwords <class 'float'>\n",
      "wordstress <class 'float'>\n",
      "melismastate <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "for col in df_phrase.columns:\n",
    "    t = type(df_phrase[col][0])\n",
    "    if t != list:\n",
    "        print(col, t)\n",
    "\n",
    "# On cherche les colonnes qui ne sont pas des listes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7302 séquences avec des paroles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsequences(df, length=8, reverse=False):\n",
    "    \"\"\"\n",
    "    Divise les colonnes de type liste d'un DataFrame en sous-séquences de taille `length`,\n",
    "    en excluant les sous-séquences dont la longueur est inférieure à `length`.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Le DataFrame d'entrée contenant des colonnes avec des listes.\n",
    "        length (int): La longueur des sous-séquences souhaitées.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un nouveau DataFrame contenant les sous-séquences comme lignes.\n",
    "    \"\"\"\n",
    "    subsequences = []\n",
    "\n",
    "    #on itere sur toutes les lignes de notre dataframe (donc sur chaque séquence)\n",
    "    for _, row in df.iterrows():\n",
    "        # dans les valeurs pour chaque attribut, on récupère la liste de taille minimale de notre séquence actuelle\n",
    "        # pour ne pas avoir une sous séquence ou il n'y aura plus de valeurs à récupérer\n",
    "\n",
    "        min_length = min(len(row[col]) for col in df.columns)\n",
    "\n",
    "        if not reverse:\n",
    "            # on prend portion par portion de notes ( longueur length ) pour diviser notre séquence\n",
    "            for start_idx in range(0, min_length, length):\n",
    "                # pour chaque portion de notes on créé notre sous séquence en reprenant les valeurs pour chaque attributs mais \n",
    "                # aux indices de la portion de notes qui nous interesse\n",
    "                subsequence = {\n",
    "                    col: row[col][start_idx:start_idx + length]\n",
    "                    for col in df.columns\n",
    "                }\n",
    "                # si toutes les valeurs sont complétées et si la longueur des sous séquences est égale à length, on peut ajouter la sous séquence à notre liste de sous sequences\n",
    "                if all(len(subsequence[col]) == length for col in df.columns):\n",
    "                    subsequences.append(subsequence)\n",
    "\n",
    "        else:\n",
    "            for start_idx in range(min_length, 0, -length):\n",
    "                subsequence = {\n",
    "                    col: row[col][start_idx - length:start_idx]\n",
    "                    for col in df.columns\n",
    "                }\n",
    "                if all(len(subsequence[col]) == length for col in df.columns):\n",
    "                    subsequences.append(subsequence)\n",
    "\n",
    "    # on en créé un dataframe\n",
    "    return pd.DataFrame(subsequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La cellule du dessous montre un test pour voir toutes les valeurs possibles dans les listes d'une colone. Value_counts() ne fonctionne pas car les attributs sont des listes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2/4', '4/4', '6/8', '3/4', '3/8', '5/8', '7/8', '2/2', '12/8', '8/16', None, '6/4', '3/2', '3/16', '9/8', '9/4', '4/2', '5/4', '4/8', '8/8', '10/8', '2/8', '1/4', '7/4', '22/8', '2/16', '8/4', '13/8', '19/16', '6/2', '1/2', '2/1', '10/4', '10/2', '12/2', '16/2', '5/2']\n"
     ]
    }
   ],
   "source": [
    "# toutes les valeurs possibles de la colonne 'timesignature' dans le DataFrame\n",
    "timesignature = []\n",
    "for x in df_phrase['timesignature']:\n",
    "    for y in x:\n",
    "        if y not in timesignature:\n",
    "            timesignature.append(y)\n",
    "print(timesignature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On continue d'analyser les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midipitch: [72, 73, 74, 72, 70, 69, 65, 69, 69, 69, 69, 74, 72, 60, 62, 64, 65, 67, 69, 70, 72, 74, 76, 79, 79, 79, 79, 60, 65, 67, 69, 69, 69, 60, 65, 67, 69, 69, 69, 72, 74, 72, 67, 69, 70, 69, 69, 60, 65, 67, 69, 69, 69, 60, 65, 67, 67, 69, 72, 74, 72, 67, 67, 72, 70, 67, 65, 74, 74, 76, 77, 76, 77, 74, 72, 69, 70, 70, 72, 67, 69, 70, 67, 69, 74, 72, 74, 74, 76, 77, 76, 77, 74, 72, 69, 69, 69, 67, 74, 72, 64, 65, 72, 72, 72, 74, 72, 70, 67, 65, 69, 69, 69, 69, 69, 67, 70, 70, 70, 70, 70, 69, 72, 72, 72, 72, 72, 72, 74, 72, 70, 67, 65, 69, 69, 69, 69, 69, 67, 74, 72, 64, 65]\n",
      "chromaticinterval: [None, 1, 1, -2, -2, -1, -4, 4, 0, 0, 0, 5, -2, -12, 2, 2, 1, 2, 2, 1, 2, 2, 2, 3, 0, 0, 0, -19, 5, 2, 2, 0, 0, -9, 5, 2, 2, 0, 0, 3, 2, -2, -5, 2, 1, -1, 0, -9, 5, 2, 2, 0, 0, -9, 5, 2, 0, 2, 3, 2, -2, -5, 0, 5, -2, -3, -2, 9, 0, 2, 1, -1, 1, -3, -2, -3, 1, 0, 2, -5, 2, 1, -3, 2, 5, -2, 2, 0, 2, 1, -1, 1, -3, -2, -3, 0, 0, -2, 7, -2, -8, 1, 7, 0, 0, 2, -2, -2, -3, -2, 4, 0, 0, 0, 0, -2, 3, 0, 0, 0, 0, -1, 3, 0, 0, 0, 0, 0, 2, -2, -2, -3, -2, 4, 0, 0, 0, 0, -2, 7, -2, -8, 1]\n",
      "tonic: ['F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "mode: ['major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major']\n",
      "timesignature: ['4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4', '4/4']\n",
      "beatstrength: [0.25, 0.0625, 1.0, 0.25, 0.5, 0.25, 1.0, 0.125, 0.0625, 0.25, 0.125, 0.5, 1.0, 0.125, 0.0625, 0.25, 0.0625, 0.125, 0.0625, 0.5, 0.125, 0.25, 0.125, 1.0, 0.125, 0.0625, 0.25, 0.125, 0.25, 0.125, 1.0, 0.125, 0.5, 0.0625, 0.25, 0.0625, 1.0, 0.25, 0.5, 0.0625, 0.25, 0.0625, 1.0, 0.0625, 0.25, 0.0625, 1.0, 0.5, 0.25, 0.0625, 1.0, 0.25, 0.5, 0.0625, 0.25, 0.125, 1.0, 0.25, 0.0625, 0.25, 0.0625, 1.0, 0.5, 0.0625, 0.25, 0.0625, 1.0, 1.0, 0.25, 0.0625, 0.5, 0.0625, 0.25, 0.0625, 1.0, 0.5, 1.0, 0.25, 0.0625, 0.5, 0.0625, 0.25, 0.0625, 1.0, 0.25, 0.5, 1.0, 0.25, 0.0625, 0.5, 0.0625, 0.25, 0.0625, 1.0, 0.5, 0.25, 0.0625, 1.0, 0.25, 0.5, 0.25, 1.0, 0.125, 0.25, 0.125, 1.0, 0.25, 0.5, 0.25, 1.0, 0.125, 0.0625, 0.25, 0.125, 0.5, 1.0, 0.125, 0.0625, 0.25, 0.125, 0.5, 1.0, 0.125, 0.0625, 0.25, 0.125, 0.25, 0.0625, 1.0, 0.25, 0.5, 0.25, 1.0, 0.125, 0.0625, 0.25, 0.125, 0.5, 1.0, 0.25, 0.5, 0.25, 1.0]\n",
      "=====================================\n",
      "duration: [0.75, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.75, 0.25, 0.75, 0.25, 1.0, 1.0, 0.75, 0.25, 0.75, 0.25, 2.75, 0.25, 0.75, 0.25, 2.0, 1.0, 0.75, 0.25, 1.0, 1.0, 0.75, 0.25, 0.5, 0.5, 1.0, 1.75, 0.25, 0.75, 0.25, 2.0, 0.75, 0.25, 0.75, 0.25, 3.0, 1.0, 0.75, 0.25, 0.75, 0.25, 0.75, 0.25, 2.0, 2.0, 1.0, 0.75, 0.25, 0.75, 0.25, 0.75, 0.25, 1.0, 1.0, 1.0, 1.0, 0.75, 0.25, 0.75, 0.25, 0.75, 0.25, 2.0, 1.0, 0.75, 0.25, 1.0, 1.0, 1.0, 1.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 0.5, 0.25, 0.25, 0.5, 0.5, 0.75, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0]\n",
      "durationcontour: [None, '-', '+', '=', '=', '=', '-', '-', '=', '+', '=', '+', '-', '-', '=', '=', '=', '=', '=', '+', '=', '=', '=', '=', '-', '=', '+', '=', '=', '=', '=', '+', '-', '-', '+', '-', '+', '=', '-', '-', '+', '-', '+', '-', '+', '-', '+', '-', '-', '-', '+', '=', '-', '-', '+', '=', '+', '+', '-', '+', '-', '+', '-', '-', '+', '-', '+', '-', '-', '-', '+', '-', '+', '-', '+', '=', '-', '-', '-', '+', '-', '+', '-', '+', '=', '=', '=', '-', '-', '+', '-', '+', '-', '+', '-', '-', '-', '+', '=', '=', '=', '+', '-', '=', '=', '=', '=', '=', '=', '=', '-', '=', '+', '=', '+', '-', '-', '=', '+', '=', '+', '-', '-', '=', '+', '=', '+', '-', '+', '=', '=', '=', '=', '-', '=', '+', '=', '+', '-', '=', '=', '=', '+']\n",
      "IOI: [0.75, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 1.5, 0.5, 0.5, 0.5, 0.5, 1.5, 0.75, 0.25, 0.75, 0.25, 1.0, 1.0, 0.75, 0.25, 0.75, 0.25, 2.75, 0.25, 0.75, 0.25, 2.0, 1.0, 0.75, 0.25, 1.0, 1.0, 0.75, 0.25, 0.5, 0.5, 1.0, 1.75, 0.25, 0.75, 0.25, 2.0, 0.75, 0.25, 0.75, 0.25, 4.0, 1.0, 0.75, 0.25, 0.75, 0.25, 0.75, 0.25, 2.0, 2.0, 1.0, 0.75, 0.25, 0.75, 0.25, 0.75, 0.25, 1.0, 1.0, 2.0, 1.0, 0.75, 0.25, 0.75, 0.25, 0.75, 0.25, 2.0, 1.0, 0.75, 0.25, 1.0, 1.0, 1.0, 1.0, 2.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 0.5, 0.25, 0.25, 0.5, 1.5, 0.75, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 0.25, 0.5, 0.5, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0]\n",
      "IOR: [None, 0.3333333333333333, 4.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 2.0, 1.0, 4.0, 0.25, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 6.0, 0.3333333333333333, 1.0, 1.0, 1.0, 3.0, 0.5, 0.3333333333333333, 3.0, 0.3333333333333333, 4.0, 1.0, 0.75, 0.3333333333333333, 3.0, 0.3333333333333333, 11.0, 0.09090909090909091, 3.0, 0.3333333333333333, 8.0, 0.5, 0.75, 0.3333333333333333, 4.0, 1.0, 0.75, 0.3333333333333333, 2.0, 1.0, 2.0, 1.75, 0.14285714285714285, 3.0, 0.3333333333333333, 8.0, 0.375, 0.3333333333333333, 3.0, 0.3333333333333333, 16.0, 0.25, 0.75, 0.3333333333333333, 3.0, 0.3333333333333333, 3.0, 0.3333333333333333, 8.0, 1.0, 0.5, 0.75, 0.3333333333333333, 3.0, 0.3333333333333333, 3.0, 0.3333333333333333, 4.0, 1.0, 2.0, 0.5, 0.75, 0.3333333333333333, 3.0, 0.3333333333333333, 3.0, 0.3333333333333333, 8.0, 0.5, 0.75, 0.3333333333333333, 4.0, 1.0, 1.0, 1.0, 2.5, 0.2, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 2.0, 1.0, 4.0, 0.25, 0.5, 1.0, 2.0, 1.0, 4.0, 0.25, 0.5, 1.0, 2.0, 3.0, 0.5, 0.3333333333333333, 4.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 2.0, 1.0, 4.0, 0.5, 1.0, 1.0, 1.0, 4.0]\n",
      "=====================================\n",
      "beatfraction: ['3/4', '1/4', '1', '1', '1', '1', '1/2', '1/4', '1/4', '1/2', '1/2', '2', '1/2', '1/4', '1/4', '1/4', '1/4', '1/4', '1/4', '1/2', '1/2', '1/2', '1/2', '1/2', '1/4', '1/4', '1/2', '1/2', '1/2', '1/2', '1/2', '1', '3/4', '1/4', '3/4', '1/4', '1', '1', '3/4', '1/4', '3/4', '1/4', '11/4', '1/4', '3/4', '1/4', '2', '1', '3/4', '1/4', '1', '1', '3/4', '1/4', '1/2', '1/2', '1', '7/4', '1/4', '3/4', '1/4', '2', '3/4', '1/4', '3/4', '1/4', '3', '1', '3/4', '1/4', '3/4', '1/4', '3/4', '1/4', '2', '2', '1', '3/4', '1/4', '3/4', '1/4', '3/4', '1/4', '1', '1', '1', '1', '3/4', '1/4', '3/4', '1/4', '3/4', '1/4', '2', '1', '3/4', '1/4', '1', '1', '1', '1', '2', '1/2', '1/2', '1/2', '1/2', '1/2', '1/2', '1/2', '1/2', '1/4', '1/4', '1/2', '1/2', '2', '1/2', '1/4', '1/4', '1/2', '1/2', '2', '1/2', '1/4', '1/4', '1/2', '1/2', '3/4', '1/4', '1/2', '1/2', '1/2', '1/2', '1/2', '1/4', '1/4', '1/2', '1/2', '2', '1', '1', '1', '1', '3']\n",
      "beat_str: ['4', '4', '1', '2', '3', '4', '1', '1', '1', '2', '2', '3', '1', '1', '1', '2', '2', '2', '2', '3', '3', '4', '4', '1', '1', '1', '2', '3', '4', '4', '1', '1', '3', '3', '4', '4', '1', '2', '3', '3', '4', '4', '1', '3', '4', '4', '1', '3', '4', '4', '1', '2', '3', '3', '4', '4', '1', '2', '3', '4', '4', '1', '3', '3', '4', '4', '1', '1', '2', '2', '3', '3', '4', '4', '1', '3', '1', '2', '2', '3', '3', '4', '4', '1', '2', '3', '1', '2', '2', '3', '3', '4', '4', '1', '3', '4', '4', '1', '2', '3', '4', '1', '3', '4', '4', '1', '2', '3', '4', '1', '1', '1', '2', '2', '3', '1', '1', '1', '2', '2', '3', '1', '1', '1', '2', '2', '4', '4', '1', '2', '3', '4', '1', '1', '1', '2', '2', '3', '1', '2', '3', '4', '1']\n",
      "beat_fraction_str: ['0', '3/4', '0', '0', '0', '0', '0', '1/2', '3/4', '0', '1/2', '0', '0', '1/2', '3/4', '0', '1/4', '1/2', '3/4', '0', '1/2', '0', '1/2', '0', '1/2', '3/4', '0', '1/2', '0', '1/2', '0', '1/2', '0', '3/4', '0', '3/4', '0', '0', '0', '3/4', '0', '3/4', '0', '3/4', '0', '3/4', '0', '0', '0', '3/4', '0', '0', '0', '3/4', '0', '1/2', '0', '0', '3/4', '0', '3/4', '0', '0', '3/4', '0', '3/4', '0', '0', '0', '3/4', '0', '3/4', '0', '3/4', '0', '0', '0', '0', '3/4', '0', '3/4', '0', '3/4', '0', '0', '0', '0', '0', '3/4', '0', '3/4', '0', '3/4', '0', '0', '0', '3/4', '0', '0', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '0', '0', '1/2', '3/4', '0', '1/2', '0', '0', '1/2', '3/4', '0', '1/2', '0', '0', '1/2', '3/4', '0', '1/2', '0', '3/4', '0', '0', '0', '0', '0', '1/2', '3/4', '0', '1/2', '0', '0', '0', '0', '0', '0']\n",
      "beat: [4.0, 4.75, 1.0, 2.0, 3.0, 4.0, 1.0, 1.5, 1.75, 2.0, 2.5, 3.0, 1.0, 1.5, 1.75, 2.0, 2.25, 2.5, 2.75, 3.0, 3.5, 4.0, 4.5, 1.0, 1.5, 1.75, 2.0, 3.5, 4.0, 4.5, 1.0, 1.5, 3.0, 3.75, 4.0, 4.75, 1.0, 2.0, 3.0, 3.75, 4.0, 4.75, 1.0, 3.75, 4.0, 4.75, 1.0, 3.0, 4.0, 4.75, 1.0, 2.0, 3.0, 3.75, 4.0, 4.5, 1.0, 2.0, 3.75, 4.0, 4.75, 1.0, 3.0, 3.75, 4.0, 4.75, 1.0, 1.0, 2.0, 2.75, 3.0, 3.75, 4.0, 4.75, 1.0, 3.0, 1.0, 2.0, 2.75, 3.0, 3.75, 4.0, 4.75, 1.0, 2.0, 3.0, 1.0, 2.0, 2.75, 3.0, 3.75, 4.0, 4.75, 1.0, 3.0, 4.0, 4.75, 1.0, 2.0, 3.0, 4.0, 1.0, 3.5, 4.0, 4.5, 1.0, 2.0, 3.0, 4.0, 1.0, 1.5, 1.75, 2.0, 2.5, 3.0, 1.0, 1.5, 1.75, 2.0, 2.5, 3.0, 1.0, 1.5, 1.75, 2.0, 2.5, 4.0, 4.75, 1.0, 2.0, 3.0, 4.0, 1.0, 1.5, 1.75, 2.0, 2.5, 3.0, 1.0, 2.0, 3.0, 4.0, 1.0]\n",
      "=====================================\n",
      "restduration_frac: [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '1', None, None, None, None, '1/2', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '1', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '1', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '1/2', None, None, None, '1/2', '1/2', '1/2', '1/2', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '1', None, None, '1/2', '1/2', '1/2', '1/2', None, None, None, None, None, None, None, None, None, None, '1']\n",
      "phrase_ix: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "=====================================\n",
      "phrasepos [0.0, 0.107143, 0.142857, 0.285714, 0.428571, 0.571429, 0.714286, 0.785714, 0.821429, 0.857143, 0.928571, 1.0, 0.0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1.0, 0.0, 0.066667, 0.133333, 0.2, 0.266667, 0.466667, 0.566667, 0.6, 0.7, 0.733333, 0.866667, 1.0, 0.0, 0.047619, 0.190476, 0.238095, 0.761905, 0.809524, 0.952381, 1.0, 0.0, 0.142857, 0.25, 0.285714, 0.428571, 0.571429, 0.678571, 0.714286, 0.785714, 0.857143, 1.0, 0.0, 0.047619, 0.190476, 0.238095, 0.619048, 0.761905, 0.809524, 0.952381, 1.0, 0.0, 0.166667, 0.291667, 0.333333, 0.458333, 0.5, 0.625, 0.666667, 1.0, 0.0, 0.166667, 0.291667, 0.333333, 0.458333, 0.5, 0.625, 0.666667, 0.833333, 1.0, 0.0, 0.166667, 0.291667, 0.333333, 0.458333, 0.5, 0.625, 0.666667, 1.0, 0.0, 0.15, 0.2, 0.4, 0.6, 0.8, 1.0, 0.0, 0.033333, 0.066667, 0.1, 0.166667, 0.233333, 0.3, 0.366667, 0.4, 0.416667, 0.433333, 0.466667, 0.5, 0.633333, 0.666667, 0.683333, 0.7, 0.733333, 0.766667, 0.9, 0.933333, 0.95, 0.966667, 1.0, 0.0, 0.057692, 0.076923, 0.153846, 0.230769, 0.307692, 0.384615, 0.423077, 0.442308, 0.461538, 0.5, 0.538462, 0.692308, 0.769231, 0.846154, 0.923077, 1.0]\n",
      "phrase_end [False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n",
      "=====================================\n",
      "beatinphrase ['-1', '-1/4', '0', '1', '2', '3', '4', '9/2', '19/4', '5', '11/2', '6', '0', '1/2', '3/4', '1', '5/4', '3/2', '7/4', '2', '5/2', '3', '7/2', '4', '9/2', '19/4', '5', '-3/2', '-1', '-1/2', '0', '1/2', '2', '11/4', '3', '15/4', '4', '5', '6', '-5/4', '-1', '-1/4', '0', '11/4', '3', '15/4', '4', '-2', '-1', '-1/4', '0', '1', '2', '11/4', '3', '7/2', '4', '5', '-5/4', '-1', '-1/4', '0', '2', '11/4', '3', '15/4', '4', '0', '1', '7/4', '2', '11/4', '3', '15/4', '4', '6', '0', '1', '7/4', '2', '11/4', '3', '15/4', '4', '5', '6', '0', '1', '7/4', '2', '11/4', '3', '15/4', '4', '6', '-1', '-1/4', '0', '1', '2', '3', '4', '-3/2', '-1', '-1/2', '0', '1', '2', '3', '4', '9/2', '19/4', '5', '11/2', '6', '8', '17/2', '35/4', '9', '19/2', '10', '12', '25/2', '51/4', '13', '27/2', '-1', '-1/4', '0', '1', '2', '3', '4', '9/2', '19/4', '5', '11/2', '6', '8', '9', '10', '11', '12']\n",
      "beatinphrase_end ['-5', '-17/4', '-4', '-3', '-2', '-1', '0', '1/2', '3/4', '1', '3/2', '2', '-4', '-7/2', '-13/4', '-3', '-11/4', '-5/2', '-9/4', '-2', '-3/2', '-1', '-1/2', '0', '1/2', '3/4', '1', '-11/2', '-5', '-9/2', '-4', '-7/2', '-2', '-5/4', '-1', '-1/4', '0', '1', '2', '-21/4', '-5', '-17/4', '-4', '-5/4', '-1', '-1/4', '0', '-6', '-5', '-17/4', '-4', '-3', '-2', '-5/4', '-1', '-1/2', '0', '1', '-21/4', '-5', '-17/4', '-4', '-2', '-5/4', '-1', '-1/4', '0', '-4', '-3', '-9/4', '-2', '-5/4', '-1', '-1/4', '0', '2', '-4', '-3', '-9/4', '-2', '-5/4', '-1', '-1/4', '0', '1', '2', '-4', '-3', '-9/4', '-2', '-5/4', '-1', '-1/4', '0', '2', '-5', '-17/4', '-4', '-3', '-2', '-1', '0', '-27/2', '-13', '-25/2', '-12', '-11', '-10', '-9', '-8', '-15/2', '-29/4', '-7', '-13/2', '-6', '-4', '-7/2', '-13/4', '-3', '-5/2', '-2', '0', '1/2', '3/4', '1', '3/2', '-13', '-49/4', '-12', '-11', '-10', '-9', '-8', '-15/2', '-29/4', '-7', '-13/2', '-6', '-4', '-3', '-2', '-1', '0']\n",
      "=====================================\n",
      "melismastate nan\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "j = 0\n",
    "\n",
    "print(\"midipitch:\", df_phrase['midipitch'][i][:])\n",
    "print(\"chromaticinterval:\", df_phrase['chromaticinterval'][i][:])\n",
    "print(\"tonic:\", df_phrase['tonic'][i][:])\n",
    "print(\"mode:\", df_phrase['mode'][i][:])\n",
    "\n",
    "# print(\"scaledegree:\", df_phrase['scaledegree'][i][:])\n",
    "print(\"timesignature:\", df_phrase['timesignature'][i][:])\n",
    "print(\"beatstrength:\", df_phrase['beatstrength'][i][:])\n",
    "# print(\"metriccontour:\", df_phrase['metriccontour'][i][:])\n",
    "# print(\"imaweight:\", df_phrase['imaweight'][i][:])\n",
    "# print(\"imacontour:\", df_phrase['imacontour'][i][:])\n",
    "print(\"=====================================\")\n",
    "print(\"duration:\", df_phrase['duration'][i][:])\n",
    "# print(\"duration_frac:\", df_phrase['duration_frac'][i][:])\n",
    "# print(\"duration_fullname:\", df_phrase['duration_fullname'][i][:])\n",
    "print(\"durationcontour:\", df_phrase['durationcontour'][i][:])\n",
    "print(\"IOI:\", df_phrase['IOI'][i][:])\n",
    "print(\"IOR:\", df_phrase['IOR'][i][:])\n",
    "# print(\"onsettick:\", df_phrase['onsettick'][i][:]) # onsettick représente le temps de la note en ticks mais ne sert pas dans notre cas car ne donne aucune information utiles, comme un ID\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"beatfraction:\", df_phrase['beatfraction'][i][:]) # durée de la note\n",
    "print(\"beat_str:\", df_phrase['beat_str'][i][:])\n",
    "print(\"beat_fraction_str:\", df_phrase['beat_fraction_str'][i][:])\n",
    "print(\"beat:\", df_phrase['beat'][i][:]) # beat_str + beat_fraction_str\n",
    "# print(\"songpos:\", df_phrase['songpos'][i][:]) # position de la note dans la chanson similaire à onsettick\n",
    "\n",
    "print(\"=====================================\")\n",
    "# print(\"beatinsong:\", df_phrase['beatinsong'][i][:]) # meme chose que pour songpos et onsettick\n",
    "# print(\"nextisrest:\", df_phrase['nextisrest'][i][:])\n",
    "print(\"restduration_frac:\", df_phrase['restduration_frac'][i][:]) # plus précis que nextisrest\n",
    "print(\"phrase_ix:\", df_phrase['phrase_ix'][i][:]) #numero de la phrase, inutile (id)\n",
    "print(\"=====================================\")\n",
    "print(\"phrasepos\", df_phrase['phrasepos'][i][:]) # position de la note dans la phrase\n",
    "print(\"phrase_end\", df_phrase['phrase_end'][i][:]) # indique si la note est la fin de la phrase\n",
    "print(\"=====================================\")\n",
    "print(\"beatinphrase\", df_phrase['beatinphrase'][i][:]) \n",
    "print(\"beatinphrase_end\", df_phrase['beatinphrase_end'][i][:])\n",
    "print(\"=====================================\")\n",
    "print(\"melismastate\", df_phrase['melismastate'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs phrasepos et phrase_end donnent explicitement une indication sur la fin de phrase. beatinphrase et beatinphrase_end donnent également des indications explicites sur le début et la fin des phrases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on remarque qu'il y a des features qui sont équivalentes comme le `pitch` et le `midipitch`. Ce dernier n'est qu'une représentation du premier en midi, c'est-à-dire en entier. On pourra donc omettre le pitch et ne garder que le midipitch car il est plus simple à manipuler.\n",
    "\n",
    "on a C5 = 72 et C#5 = 73 car c'est la note juste après C5\n",
    "\n",
    "On doit chercher toutes les features qui sont corrélées pour ne pas utiliser des features inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liste des features corrélées selon la doc : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`pitch`, `midipitch`, `pitch40`, `diatonicpitch`] -> `midipitch` : hauteur de la note\n",
    "\n",
    "[`contour3`, `contour5`, `diatonicinterval`, `chromaticinterval`] -> `chromaticinterval` : variation par rapport à la note précédente\n",
    "\n",
    "[`tonic`] -> `tonic`\n",
    "\n",
    "[`mode`] -> `mode`\n",
    "\n",
    "[`scaledegree`, `scaledegreespecifier`] -> `scaledegree` : peut-être les 2 ?\n",
    "\n",
    "[`timesignature`] -> `timesignature`\n",
    "\n",
    "[`beatstrength`] -> `beatstrength`\n",
    "\n",
    "[`mtriccontour`] -> `metriccontour`\n",
    "\n",
    "[`imaweight`] -> `imaweight`\n",
    "\n",
    "[`imacontour`] -> `imacontour`\n",
    "\n",
    "[`duration`, `duration_frac`, `duration_fullname`] -> `duration` : durée de la note (forme de fraction et nom chaine de caractère)\n",
    "\n",
    "[`durationcontour`] -> `durationcontour`\n",
    "\n",
    "[`IOI`, `IOI_frac`] -> `IOI`\n",
    "\n",
    "[`IOR`, `IOR_frac`] -> `IOR` : ratio entre IOI précédent et IOI actuel\n",
    "\n",
    "[`beatfraction`] -> `beatfraction` : durée de la note\n",
    "\n",
    "[`beat_fraction_str`, `beat_str`, `beat`] -> `beat` : `beat_fraction_str` + `beat_str`\n",
    "\n",
    "[`nextisrest`, `restduration_frac`] -> `restduration_frac` : pause qui suit la note\n",
    "\n",
    "[`phrasepos`, `phrase_end`] -> `phrase_pos` : fin de la phrase\n",
    "\n",
    "[`beatinphrase`, `beatinphrase_end`] -> les deux sont similaires, donne info sur fin de phrase donc peut être à ne pas prendre en compte\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[`onsettick`, `songpos`, `beatinsong`, `phrase_ix`] -> aucune features utile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# premiere selection des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(['midipitch', 'chromaticinterval', 'scaledegree', 'timesignature', 'beatstrength', 'metriccontour', 'imaweight', 'imacontour', 'duration', 'durationcontour', 'beatfraction', 'beat', 'restduration_frac', 'phrase_end'])\n",
    "new_df = df_phrase[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On découpe notre dataset en sous sequences de 8 notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midipitch</th>\n",
       "      <th>chromaticinterval</th>\n",
       "      <th>scaledegree</th>\n",
       "      <th>timesignature</th>\n",
       "      <th>beatstrength</th>\n",
       "      <th>metriccontour</th>\n",
       "      <th>imaweight</th>\n",
       "      <th>imacontour</th>\n",
       "      <th>duration</th>\n",
       "      <th>durationcontour</th>\n",
       "      <th>beatfraction</th>\n",
       "      <th>beat</th>\n",
       "      <th>restduration_frac</th>\n",
       "      <th>phrase_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64, 60, 57, 55, 60, 60, 62, 60]</td>\n",
       "      <td>[None, -4, -3, -2, 5, 0, 2, -2]</td>\n",
       "      <td>[3, 1, 6, 5, 1, 1, 2, 1]</td>\n",
       "      <td>[2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]</td>\n",
       "      <td>[1.0, 0.5, 0.25, 1.0, 0.125, 0.5, 1.0, 0.5]</td>\n",
       "      <td>[None, -, -, +, -, +, +, -]</td>\n",
       "      <td>[0.798013, 0.663907, 0.150662, 0.945364, 0.013...</td>\n",
       "      <td>[None, -, -, +, -, +, +, -]</td>\n",
       "      <td>[1.0, 0.5, 0.5, 0.75, 0.25, 1.0, 1.0, 0.5]</td>\n",
       "      <td>[None, -, =, +, -, +, =, -]</td>\n",
       "      <td>[1, 1/2, 1/2, 3/4, 1/4, 1, 1, 1/2]</td>\n",
       "      <td>[1.0, 2.0, 2.5, 1.0, 1.75, 2.0, 1.0, 2.0]</td>\n",
       "      <td>[None, None, None, None, None, None, None, None]</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[62, 64, 57, 55, 55, 54, 55, 57]</td>\n",
       "      <td>[2, 2, -7, -2, 0, -1, 1, 2]</td>\n",
       "      <td>[2, 3, 6, 5, 5, 4, 5, 6]</td>\n",
       "      <td>[2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]</td>\n",
       "      <td>[0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0]</td>\n",
       "      <td>[-, +, -, +, +, -, -, +]</td>\n",
       "      <td>[0.195364, 0.812914, 0.162252, 0.627483, 0.951...</td>\n",
       "      <td>[-, +, -, +, +, -, -, +]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5]</td>\n",
       "      <td>[=, =, =, +, =, -, =, =]</td>\n",
       "      <td>[1/2, 1/2, 1/2, 1, 1, 1/2, 1/2, 1/2]</td>\n",
       "      <td>[2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0]</td>\n",
       "      <td>[None, None, None, None, None, None, None, None]</td>\n",
       "      <td>[False, False, False, True, False, False, Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[65, 64, 62, 64, 62, 55, 62, 64]</td>\n",
       "      <td>[8, -1, -2, 2, -2, -7, 7, 2]</td>\n",
       "      <td>[4, 3, 2, 3, 2, 5, 2, 3]</td>\n",
       "      <td>[2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]</td>\n",
       "      <td>[0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 1.0, 0.5]</td>\n",
       "      <td>[-, +, +, -, -, +, =, -]</td>\n",
       "      <td>[0.183775, 0.642384, 0.837748, 0.692053, 0.25,...</td>\n",
       "      <td>[-, +, +, -, -, +, -, -]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5]</td>\n",
       "      <td>[=, +, =, -, =, +, =, -]</td>\n",
       "      <td>[1/2, 1, 1, 1/2, 1/2, 1, 1, 1/2]</td>\n",
       "      <td>[1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.0, 2.0]</td>\n",
       "      <td>[None, None, None, None, None, 1, None, None]</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[62, 60, 57, 55, 64, 65, 64, 57]</td>\n",
       "      <td>[-2, -2, -3, -2, 9, 1, -1, -7]</td>\n",
       "      <td>[2, 1, 6, 5, 3, 4, 3, 6]</td>\n",
       "      <td>[2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]</td>\n",
       "      <td>[0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0]</td>\n",
       "      <td>[-, +, -, +, +, -, -, +]</td>\n",
       "      <td>[0.243377, 0.870861, 0.205298, 0.630795, 0.917...</td>\n",
       "      <td>[-, +, -, +, +, -, -, +]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5]</td>\n",
       "      <td>[=, =, =, +, =, -, =, =]</td>\n",
       "      <td>[1/2, 1/2, 1/2, 1, 1, 1/2, 1/2, 1/2]</td>\n",
       "      <td>[2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0]</td>\n",
       "      <td>[None, None, None, None, None, None, None, None]</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[64, 62, 55, 57, 55, 55, 65, 64]</td>\n",
       "      <td>[7, -2, -7, 2, -2, 0, 10, -1]</td>\n",
       "      <td>[3, 2, 5, 6, 5, 5, 4, 3]</td>\n",
       "      <td>[2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]</td>\n",
       "      <td>[0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5]</td>\n",
       "      <td>[-, +, +, -, -, +, -, +]</td>\n",
       "      <td>[0.162252, 0.652318, 0.84106, 0.652318, 0.1837...</td>\n",
       "      <td>[-, +, +, -, -, +, -, +]</td>\n",
       "      <td>[0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0]</td>\n",
       "      <td>[=, +, =, -, =, =, =, +]</td>\n",
       "      <td>[1/2, 1, 1, 1/2, 1/2, 1/2, 1/2, 1]</td>\n",
       "      <td>[1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0]</td>\n",
       "      <td>[None, None, None, None, None, None, None, None]</td>\n",
       "      <td>[False, True, False, False, False, False, Fals...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          midipitch                chromaticinterval  \\\n",
       "0  [64, 60, 57, 55, 60, 60, 62, 60]  [None, -4, -3, -2, 5, 0, 2, -2]   \n",
       "1  [62, 64, 57, 55, 55, 54, 55, 57]      [2, 2, -7, -2, 0, -1, 1, 2]   \n",
       "2  [65, 64, 62, 64, 62, 55, 62, 64]     [8, -1, -2, 2, -2, -7, 7, 2]   \n",
       "3  [62, 60, 57, 55, 64, 65, 64, 57]   [-2, -2, -3, -2, 9, 1, -1, -7]   \n",
       "4  [64, 62, 55, 57, 55, 55, 65, 64]    [7, -2, -7, 2, -2, 0, 10, -1]   \n",
       "\n",
       "                scaledegree                             timesignature  \\\n",
       "0  [3, 1, 6, 5, 1, 1, 2, 1]  [2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]   \n",
       "1  [2, 3, 6, 5, 5, 4, 5, 6]  [2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]   \n",
       "2  [4, 3, 2, 3, 2, 5, 2, 3]  [2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]   \n",
       "3  [2, 1, 6, 5, 3, 4, 3, 6]  [2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]   \n",
       "4  [3, 2, 5, 6, 5, 5, 4, 3]  [2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4, 2/4]   \n",
       "\n",
       "                                  beatstrength                metriccontour  \\\n",
       "0  [1.0, 0.5, 0.25, 1.0, 0.125, 0.5, 1.0, 0.5]  [None, -, -, +, -, +, +, -]   \n",
       "1  [0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0]     [-, +, -, +, +, -, -, +]   \n",
       "2   [0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 1.0, 0.5]     [-, +, +, -, -, +, =, -]   \n",
       "3  [0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0]     [-, +, -, +, +, -, -, +]   \n",
       "4  [0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5]     [-, +, +, -, -, +, -, +]   \n",
       "\n",
       "                                           imaweight  \\\n",
       "0  [0.798013, 0.663907, 0.150662, 0.945364, 0.013...   \n",
       "1  [0.195364, 0.812914, 0.162252, 0.627483, 0.951...   \n",
       "2  [0.183775, 0.642384, 0.837748, 0.692053, 0.25,...   \n",
       "3  [0.243377, 0.870861, 0.205298, 0.630795, 0.917...   \n",
       "4  [0.162252, 0.652318, 0.84106, 0.652318, 0.1837...   \n",
       "\n",
       "                    imacontour                                    duration  \\\n",
       "0  [None, -, -, +, -, +, +, -]  [1.0, 0.5, 0.5, 0.75, 0.25, 1.0, 1.0, 0.5]   \n",
       "1     [-, +, -, +, +, -, -, +]    [0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5]   \n",
       "2     [-, +, +, -, -, +, -, -]    [0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5]   \n",
       "3     [-, +, -, +, +, -, -, +]    [0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5]   \n",
       "4     [-, +, +, -, -, +, -, +]    [0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0]   \n",
       "\n",
       "               durationcontour                          beatfraction  \\\n",
       "0  [None, -, =, +, -, +, =, -]    [1, 1/2, 1/2, 3/4, 1/4, 1, 1, 1/2]   \n",
       "1     [=, =, =, +, =, -, =, =]  [1/2, 1/2, 1/2, 1, 1, 1/2, 1/2, 1/2]   \n",
       "2     [=, +, =, -, =, +, =, -]      [1/2, 1, 1, 1/2, 1/2, 1, 1, 1/2]   \n",
       "3     [=, =, =, +, =, -, =, =]  [1/2, 1/2, 1/2, 1, 1, 1/2, 1/2, 1/2]   \n",
       "4     [=, +, =, -, =, =, =, +]    [1/2, 1, 1, 1/2, 1/2, 1/2, 1/2, 1]   \n",
       "\n",
       "                                        beat  \\\n",
       "0  [1.0, 2.0, 2.5, 1.0, 1.75, 2.0, 1.0, 2.0]   \n",
       "1   [2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0]   \n",
       "2   [1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.0, 2.0]   \n",
       "3   [2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0]   \n",
       "4   [1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0]   \n",
       "\n",
       "                                  restduration_frac  \\\n",
       "0  [None, None, None, None, None, None, None, None]   \n",
       "1  [None, None, None, None, None, None, None, None]   \n",
       "2     [None, None, None, None, None, 1, None, None]   \n",
       "3  [None, None, None, None, None, None, None, None]   \n",
       "4  [None, None, None, None, None, None, None, None]   \n",
       "\n",
       "                                          phrase_end  \n",
       "0  [False, False, False, False, False, False, Fal...  \n",
       "1  [False, False, False, True, False, False, Fals...  \n",
       "2  [False, False, False, False, False, True, Fals...  \n",
       "3  [False, False, False, False, False, False, Fal...  \n",
       "4  [False, True, False, False, False, False, Fals...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_seqs_df = generate_subsequences(new_df, length=8)\n",
    "\n",
    "sub_seqs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certaines features ne sont pas des listes de valeur mais des strings. On va les transformer en valeur numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from fractions import Fraction\n",
    "\n",
    "def transform_features(df):\n",
    "    \"\"\"\n",
    "    Transforme les features qui ne sont pas des listes de nombres en listes de nombres.\n",
    "\n",
    "    Transformations spécifiques :\n",
    "    - 'chromaticinterval': remplace None par 0.\n",
    "    - 'tonic': encode les valeurs en vecteurs binaires selon 21 possibilités.\n",
    "    - 'mode': encode les valeurs en vecteurs binaires selon 6 possibilités.\n",
    "    - 'timesignature': convertit les fractions en nombres décimaux.\n",
    "    - 'beatfraction': convertit les fractions en nombres décimaux.\n",
    "    - 'metriccontour', 'imacontour', 'durationcontour': transforme les chaînes en 1, -1 ou 0.\n",
    "    - 'restduration_frac': convertit les fractions en nombres décimaux, remplace None par 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Le DataFrame d'entrée.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Le DataFrame transformé.\n",
    "    \"\"\"\n",
    "    if 'chromaticinterval' in df.columns:\n",
    "        # print(\"chromaticinterval\")\n",
    "        df['chromaticinterval'] = df['chromaticinterval'].apply(\n",
    "            lambda lst: [0 if val is None else val for val in lst]\n",
    "        )\n",
    "\n",
    "    if 'beatstrength' in df.columns:\n",
    "        # print(\"beatstrength\")\n",
    "        df['beatstrength'] = df['beatstrength'].apply(\n",
    "            lambda lst: [0 if val is None else val for val in lst]\n",
    "        )\n",
    "\n",
    "    if 'beat' in df.columns:\n",
    "        # print(\"beat\")\n",
    "        df['beat'] = df['beat'].apply(\n",
    "            lambda lst: [0 if val is None else val for val in lst]\n",
    "        )\n",
    "\n",
    "    if 'tonic' in df.columns:\n",
    "        # print(\"tonic\")\n",
    "        notes = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "        alterations = ['-', '', '#']\n",
    "        possible_tonics = [n + a for n in notes for a in alterations]\n",
    "        encoder = OneHotEncoder(categories=[possible_tonics], sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "        def encode_tonic(tonic_list):\n",
    "            encoded = encoder.fit_transform(np.array(tonic_list).reshape(-1, 1))\n",
    "            return encoded.tolist()\n",
    "\n",
    "        df['tonic'] = df['tonic'].apply(encode_tonic)\n",
    "\n",
    "    if 'mode' in df.columns:\n",
    "        # print(\"mode\")\n",
    "        possible_modes = ['major', 'minor', 'dorian', 'phrygian', 'lydian', 'mixolydian']\n",
    "        encoder = OneHotEncoder(categories=[possible_modes], sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "        def encode_mode(mode_list):\n",
    "            encoded = encoder.fit_transform(np.array(mode_list).reshape(-1, 1))\n",
    "            return encoded.tolist()\n",
    "\n",
    "        df['mode'] = df['mode'].apply(encode_mode)\n",
    "\n",
    "    if 'timesignature' in df.columns:\n",
    "        # print(\"timesignature\")\n",
    "        df['timesignature'] = df['timesignature'].apply(\n",
    "            lambda lst: [float(Fraction(val)) if val is not None else 0.0 for val in lst]\n",
    "        )\n",
    "\n",
    "    if 'beatfraction' in df.columns:\n",
    "        # print(\"beatfraction\")\n",
    "        df['beatfraction'] = df['beatfraction'].apply(\n",
    "            lambda lst: [float(Fraction(val)) if val is not None else 0.0 for val in lst]\n",
    "        )\n",
    "\n",
    "    def transform_contour(contour_list):\n",
    "        return [\n",
    "            1 if val == '+' else -1 if val == '-' else 0 if val in ('=', None) else val\n",
    "            for val in contour_list\n",
    "        ]\n",
    "\n",
    "    for contour_feature in ['metriccontour', 'imacontour', 'durationcontour']:\n",
    "        if contour_feature in df.columns:\n",
    "            # print(contour_feature)\n",
    "            df[contour_feature] = df[contour_feature].apply(transform_contour)\n",
    "\n",
    "    if 'restduration_frac' in df.columns:\n",
    "        # print(\"restduration_frac\")\n",
    "        df['restduration_frac'] = df['restduration_frac'].apply(\n",
    "            lambda lst: [float(Fraction(val)) if val is not None else 0.0 for val in lst]\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "# deux types d'etiquettages possibles :\n",
    "\n",
    "def transform_target_any(df): # on regarde si il y a une fin de phrase dans la sous séquence\n",
    "    \"\"\"\n",
    "    Transforme la colonne 'phrase_end' en une seule valeur binaire. 1 si il y a une fin de phrase dans la sous séquence\n",
    "    \"\"\"\n",
    "    if 'phrase_end' in df.columns:\n",
    "        # print(\"phrase_end\")\n",
    "        df['phrase_end'] = df['phrase_end'].apply(\n",
    "            lambda lst: 1 if any(val == True for val in lst) else 0\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform_target_end(df): # on regarde si la fin de phrase est à la fin de la sous séquence\n",
    "    \"\"\"\n",
    "    Transforme la colonne 'phrase_end' en une seule valeur binaire. 1 si il y a une fin de phrase à la fin de la séquence\n",
    "    \"\"\"\n",
    "    if 'phrase_end' in df.columns:\n",
    "        df['phrase_end'] = df['phrase_end'].apply(\n",
    "            lambda lst: 1 if lst[-1] == True else 0\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform_target_hybrid(df, idx):\n",
    "    \"\"\"\n",
    "    Transforme la colonne 'phrase_end' en une seule valeur binaire. 1 si il y a une fin de phrase à partir de l'indice idx\n",
    "    \"\"\"\n",
    "    idx = len(df['phrase_end'][0]) - idx\n",
    "    if 'phrase_end' in df.columns:\n",
    "        df['phrase_end'] = df['phrase_end'].apply(\n",
    "            lambda lst: 1 if True in lst[idx:] else 0\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "liste = [True, False, True, False, True, False, True, False]\n",
    "idx = len(liste) - 2\n",
    "print(idx)\n",
    "print(True in liste[idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     'chromaticinterval': [[1, 2, None, 4], [None, 2, 3, 4]],\n",
    "#     'tonic': [['C#', 'A-', 'B'], ['D', 'E', 'F#']],\n",
    "#     'mode': [['major', 'minor'], ['lydian', 'mixolydian']],\n",
    "#     'timesignature': [['1/4', '1/2', '3/4'], ['2/3', '1/8', '1/16']],\n",
    "#     'beatfraction': [['1/12', '1/3', '5/6'], ['7/8', '1/6', '1/2']],\n",
    "#     'metriccontour': [['+', '-', '='], ['-', '=', None]],\n",
    "#     'imacontour': [['+', '=', '-'], ['=', None, '+']],\n",
    "#     'durationcontour': [[None, '+', '-'], ['-', '+', '=']],\n",
    "#     'restduration_frac': [['1/4', None, '3/8'], [None, '1/16', '1/2']],\n",
    "#     'phrase_end': [[False, False, True], [False, False, False]]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# transformed_df = transform_features(df)\n",
    "\n",
    "# for col in transformed_df.columns:\n",
    "#     print(f\"{col}:\\n{transformed_df[col][1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_sub_seqs_df = transform_features(sub_seqs_df)\n",
    "# transformed_sub_seqs_df1 = transformed_sub_seqs_df.copy()\n",
    "# transformed_sub_seqs_df1 = transform_target_any(transformed_sub_seqs_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# premier test de modèle\n",
    "\n",
    "surtout pour voir si les features sont bien traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Exemple : Fonction de transformation pour des données séquentielles\n",
    "# def transform_sequence_features(df, sequence_columns):\n",
    "#     \"\"\"\n",
    "#     Transforme des colonnes contenant des listes ou vecteurs en statistiques globales.\n",
    "#     \"\"\"\n",
    "#     transformed_features = {}\n",
    "#     for col in sequence_columns:\n",
    "#         transformed_features[f'{col}_mean'] = df[col].apply(np.mean)\n",
    "#         transformed_features[f'{col}_std'] = df[col].apply(np.std)\n",
    "#         transformed_features[f'{col}_min'] = df[col].apply(np.min)\n",
    "#         transformed_features[f'{col}_max'] = df[col].apply(np.max)\n",
    "#     return pd.DataFrame(transformed_features)\n",
    "\n",
    "# # Étape 1 : Charger les données\n",
    "# sequence_columns = ['midipitch', 'chromaticinterval', 'scaledegree', \n",
    "#                     'beatstrength', 'metriccontour', 'duration']\n",
    "# target_column = 'phrase_end'\n",
    "\n",
    "# # Transformer les données\n",
    "# transformed_df = transform_sequence_features(transformed_sub_seqs_df, sequence_columns)\n",
    "# transformed_df['phrase_end'] = transformed_sub_seqs_df[target_column]\n",
    "\n",
    "# # Séparer les données en X et y\n",
    "# X = transformed_df.drop(columns=['phrase_end'])\n",
    "# y = transformed_df['phrase_end']\n",
    "\n",
    "# # Diviser en jeu d'entraînement et de test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Étape 2 : Tester plusieurs modèles\n",
    "# models = {\n",
    "#     'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "#     'SVM': SVC(),\n",
    "#     'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "#     'KNN': KNeighborsClassifier(),\n",
    "# }\n",
    "\n",
    "# # Étape 3 : Entraîner et évaluer chaque modèle\n",
    "# for name, model in models.items():\n",
    "#     pipeline = Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     y_pred = pipeline.predict(X_test)\n",
    "#     print(f\"{name}:\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(models['Random Forest'].score(X_test, y_test))\n",
    "# print(models['Logistic Regression'].score(X_test, y_test))\n",
    "# print(models['SVM'].score(X_test, y_test))\n",
    "# print(models['KNN'].score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comme on a des liste de features, on va les aplatir pour pouvoir les utiliser dans un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def flatten_row(row):\n",
    "    flattened = {}\n",
    "    for attr, values in row.items():\n",
    "        if isinstance(values, list):  # Si la valeur est une liste\n",
    "            for i, val in enumerate(values):\n",
    "                flattened[f\"{attr}_{i}\"] = val\n",
    "        else:\n",
    "            flattened[attr] = values  # Si ce n'est pas une liste\n",
    "    return flattened\n",
    "\n",
    "def flatten_dataframe(data):\n",
    "    flattened_rows = [flatten_row(row) for _, row in data.iterrows()]\n",
    "    return pd.DataFrame(flattened_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midipitch_0</th>\n",
       "      <th>midipitch_1</th>\n",
       "      <th>midipitch_2</th>\n",
       "      <th>chromaticinterval_0</th>\n",
       "      <th>chromaticinterval_1</th>\n",
       "      <th>chromaticinterval_2</th>\n",
       "      <th>phrase_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   midipitch_0  midipitch_1  midipitch_2  chromaticinterval_0  \\\n",
       "0           64           60         57.0                    0   \n",
       "1           55           60         60.0                   -2   \n",
       "2           62           60          NaN                    1   \n",
       "\n",
       "   chromaticinterval_1  chromaticinterval_2  phrase_end  \n",
       "0                   -4                 -3.0           0  \n",
       "1                    4                 -1.0           1  \n",
       "2                   -2                  NaN           0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple de données\n",
    "data = pd.DataFrame([\n",
    "    {'midipitch': [64, 60, 57], 'chromaticinterval': [0, -4, -3], 'phrase_end': 0},\n",
    "    {'midipitch': [55, 60, 60], 'chromaticinterval': [-2, 4, -1], 'phrase_end': 1},\n",
    "    {'midipitch': [62, 60], 'chromaticinterval': [1, -2], 'phrase_end': 0}\n",
    "])\n",
    "\n",
    "# Transformation\n",
    "flattened_data = flatten_dataframe(data)\n",
    "flattened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transformed_sub_seqs_df_flattened1 = flatten_dataframe(transformed_sub_seqs_df1.drop(columns=['phrase_end']))\n",
    "# transformed_sub_seqs_df_flattened1['phrase_end'] = transformed_sub_seqs_df1['phrase_end']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# premier vrai modèle\n",
    "\n",
    "test de plusieurs hyperparamètres pour voir lequel est le plus performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# X = transformed_sub_seqs_df_flattened.drop(columns=['phrase_end'])\n",
    "# y = transformed_sub_seqs_df_flattened['phrase_end']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# activation = ['tanh', 'relu']\n",
    "# solver = ['sgd']\n",
    "# alpha = [0.0001, 0.001, 0.01]\n",
    "# learning_rate = ['constant']\n",
    "# max_iter = [100, 200, 300, 400, 500]\n",
    "\n",
    "# best_score = 0\n",
    "# best_params = {}\n",
    "\n",
    "# all_scores = []\n",
    "\n",
    "# for act in activation:\n",
    "#     for sol in solver:\n",
    "#         for a in alpha:\n",
    "#             for lr in learning_rate:\n",
    "#                 for mi in max_iter:\n",
    "#                     print(f\"Training with activation={act}, solver={sol}, alpha={a}, learning_rate={lr}, max_iter={mi}\")\n",
    "#                     clf = MLPClassifier(activation=act, solver=sol, alpha=a, learning_rate=lr, max_iter=mi)\n",
    "#                     scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "#                     score = scores.mean()\n",
    "#                     all_scores.append((act, sol, a, lr, mi, score))\n",
    "#                     if score > best_score:\n",
    "#                         best_score = score\n",
    "#                         best_params = {\n",
    "#                             'activation': act,\n",
    "#                             'solver': sol,\n",
    "#                             'alpha': a,\n",
    "#                             'learning_rate': lr,\n",
    "#                             'max_iter': mi\n",
    "#                         }\n",
    "\n",
    "# print(best_score)\n",
    "# print(best_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n[('tanh', 'sgd', 0.0001, 'constant', 100, 0.6331837211870238),\\n ('tanh', 'sgd', 0.0001, 'constant', 200, 0.6267489099900372),\\n ('tanh', 'sgd', 0.0001, 'constant', 300, 0.6267355570727817),\\n ('tanh', 'sgd', 0.0001, 'constant', 400, 0.6269491582974394),\\n ('tanh', 'sgd', 0.0001, 'constant', 500, 0.6266287524500326),\\n ('tanh', 'sgd', 0.001, 'constant', 100, 0.6267489046428102),\\n ('tanh', 'sgd', 0.001, 'constant', 200, 0.6343184927877938),\\n ('tanh', 'sgd', 0.001, 'constant', 300, 0.629499054833051),\\n ('tanh', 'sgd', 0.001, 'constant', 400, 0.6267489037516056),\\n ('tanh', 'sgd', 0.001, 'constant', 500, 0.6285645377781148),\\n ('tanh', 'sgd', 0.01, 'constant', 100, 0.6263483973335517),\\n ('tanh', 'sgd', 0.01, 'constant', 200, 0.6268290061046619),\\n ('tanh', 'sgd', 0.01, 'constant', 300, 0.6287914910288234),\\n ('tanh', 'sgd', 0.01, 'constant', 400, 0.6267489046428102),\\n ('tanh', 'sgd', 0.01, 'constant', 500, 0.6266287497764191),\\n ('relu', 'sgd', 0.0001, 'constant', 100, 0.690443999872023),\\n ('relu', 'sgd', 0.0001, 'constant', 200, 0.7056097171236659),\\n ('relu', 'sgd', 0.0001, 'constant', 300, 0.6912850251172624),\\n ('relu', 'sgd', 0.0001, 'constant', 400, 0.7004565239690791),\\n ('relu', 'sgd', 0.0001, 'constant', 500, 0.7017247570108609),\\n ('relu', 'sgd', 0.001, 'constant', 100, 0.7023924812996329),\\n ('relu', 'sgd', 0.001, 'constant', 200, 0.6785339213381899),\\n ('relu', 'sgd', 0.001, 'constant', 300, 0.6907110974301316),\\n ('relu', 'sgd', 0.001, 'constant', 400, 0.6997759672264887),\\n ('relu', 'sgd', 0.001, 'constant', 500, 0.7056500958178535),\\n ('relu', 'sgd', 0.01, 'constant', 100, 0.6963313414615344),\\n ('relu', 'sgd', 0.01, 'constant', 200, 0.6869056942532191),\\n ('relu', 'sgd', 0.01, 'constant', 300, 0.6901091716619422),\\n ('relu', 'sgd', 0.01, 'constant', 400, 0.6997354557428282),\\n ('relu', 'sgd', 0.01, 'constant', 500, 0.701377864565254)]\\n \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_scores\n",
    "\n",
    "\"\"\"\n",
    "[('tanh', 'sgd', 0.0001, 'constant', 100, 0.6331837211870238),\n",
    " ('tanh', 'sgd', 0.0001, 'constant', 200, 0.6267489099900372),\n",
    " ('tanh', 'sgd', 0.0001, 'constant', 300, 0.6267355570727817),\n",
    " ('tanh', 'sgd', 0.0001, 'constant', 400, 0.6269491582974394),\n",
    " ('tanh', 'sgd', 0.0001, 'constant', 500, 0.6266287524500326),\n",
    " ('tanh', 'sgd', 0.001, 'constant', 100, 0.6267489046428102),\n",
    " ('tanh', 'sgd', 0.001, 'constant', 200, 0.6343184927877938),\n",
    " ('tanh', 'sgd', 0.001, 'constant', 300, 0.629499054833051),\n",
    " ('tanh', 'sgd', 0.001, 'constant', 400, 0.6267489037516056),\n",
    " ('tanh', 'sgd', 0.001, 'constant', 500, 0.6285645377781148),\n",
    " ('tanh', 'sgd', 0.01, 'constant', 100, 0.6263483973335517),\n",
    " ('tanh', 'sgd', 0.01, 'constant', 200, 0.6268290061046619),\n",
    " ('tanh', 'sgd', 0.01, 'constant', 300, 0.6287914910288234),\n",
    " ('tanh', 'sgd', 0.01, 'constant', 400, 0.6267489046428102),\n",
    " ('tanh', 'sgd', 0.01, 'constant', 500, 0.6266287497764191),\n",
    " ('relu', 'sgd', 0.0001, 'constant', 100, 0.690443999872023),\n",
    " ('relu', 'sgd', 0.0001, 'constant', 200, 0.7056097171236659),\n",
    " ('relu', 'sgd', 0.0001, 'constant', 300, 0.6912850251172624),\n",
    " ('relu', 'sgd', 0.0001, 'constant', 400, 0.7004565239690791),\n",
    " ('relu', 'sgd', 0.0001, 'constant', 500, 0.7017247570108609),\n",
    " ('relu', 'sgd', 0.001, 'constant', 100, 0.7023924812996329),\n",
    " ('relu', 'sgd', 0.001, 'constant', 200, 0.6785339213381899),\n",
    " ('relu', 'sgd', 0.001, 'constant', 300, 0.6907110974301316),\n",
    " ('relu', 'sgd', 0.001, 'constant', 400, 0.6997759672264887),\n",
    " ('relu', 'sgd', 0.001, 'constant', 500, 0.7056500958178535),\n",
    " ('relu', 'sgd', 0.01, 'constant', 100, 0.6963313414615344),\n",
    " ('relu', 'sgd', 0.01, 'constant', 200, 0.6869056942532191),\n",
    " ('relu', 'sgd', 0.01, 'constant', 300, 0.6901091716619422),\n",
    " ('relu', 'sgd', 0.01, 'constant', 400, 0.6997354557428282),\n",
    " ('relu', 'sgd', 0.01, 'constant', 500, 0.701377864565254)]\n",
    " \"\"\"\n",
    "\n",
    "# relu meilleur que tanh, alpha = 0.0001, learning_rate = constant, max_iter = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# on se rend compte que notre premier étiqutage n'est pas forcément le meilleur\n",
    "\n",
    "any n'est pas représentatif car une fin de phrase peut être n'importe où dans la séquence\n",
    "\n",
    "on va donc essayer de trouver une autre méthode pour étiqueter les données\n",
    "\n",
    "end : la sous séquence est une phrase si il y a une fin de phrase à la fin de la séquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant on ne va considérer comme des fins de phrase que les séquences qui ont une note en fin de phrase en fin de séquences\n",
    "# transformed_sub_seqs_df2 = transformed_sub_seqs_df.copy()\n",
    "# transformed_sub_seqs_df2 = transform_target_end(transformed_sub_seqs_df2)\n",
    "\n",
    "# print(transformed_sub_seqs_df1['phrase_end'].value_counts())\n",
    "# print(transformed_sub_seqs_df2['phrase_end'].value_counts())\n",
    "\n",
    "# transformed_sub_seqs_df_flattened2 = flatten_dataframe(transformed_sub_seqs_df2.drop(columns=['phrase_end']))\n",
    "# transformed_sub_seqs_df_flattened2['phrase_end'] = transformed_sub_seqs_df2['phrase_end']\n",
    "\n",
    "# print(transformed_sub_seqs_df_flattened2['phrase_end'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deuxième modèle avec un autre étiquetage (end)\n",
    "\n",
    "avec et sans scaler\n",
    "\n",
    "on test les 2 étiquetages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# X1 = transformed_sub_seqs_df_flattened1.drop(columns=['phrase_end'])\n",
    "# y1 = transformed_sub_seqs_df_flattened1['phrase_end']\n",
    "\n",
    "# X2 = transformed_sub_seqs_df_flattened2.drop(columns=['phrase_end'])\n",
    "# y2 = transformed_sub_seqs_df_flattened2['phrase_end']\n",
    "\n",
    "# X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# clf1 = MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200)\n",
    "# clf1.fit(X_train1, y_train1)\n",
    "# y_pred1 = clf1.predict(X_test1)\n",
    "# print(\"Model 1\")\n",
    "# print(classification_report(y_test1, y_pred1))\n",
    "# print(clf1.score(X_test1, y_test1))\n",
    "\n",
    "# clf2 = MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200)\n",
    "\n",
    "# clf2.fit(X_train2, y_train2)\n",
    "# y_pred2 = clf2.predict(X_test2)\n",
    "# print(\"Model 2\")\n",
    "# print(classification_report(y_test2, y_pred2))\n",
    "# print(clf2.score(X_test2, y_test2))\n",
    "\n",
    "# pipeline1 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "\n",
    "# pipeline1.fit(X_train1, y_train1)\n",
    "# y_pred3 = pipeline1.predict(X_test1)\n",
    "# print(\"Model 3\")\n",
    "# print(classification_report(y_test1, y_pred3))\n",
    "# print(pipeline1.score(X_test1, y_test1))\n",
    "\n",
    "# pipeline2 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "\n",
    "# pipeline2.fit(X_train2, y_train2)\n",
    "# y_pred4 = pipeline2.predict(X_test2)\n",
    "# print(\"Model 4\")\n",
    "# print(classification_report(y_test2, y_pred4))\n",
    "# print(pipeline2.score(X_test2, y_test2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on a testé avec et sans scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleur score global avec le deuxieme etiquetage mais biaisé par la classe majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, display=True):\n",
    "    plt.clf()\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    title = title.replace(' ', '_').lower()\n",
    "    plt.savefig(title + '.png')\n",
    "    if display:\n",
    "        plt.show()\n",
    "\n",
    "# plot_confusion_matrix(y_test1, y_pred1, 'Confusion matrix for model 1')\n",
    "# plot_confusion_matrix(y_test2, y_pred2, 'Confusion matrix for model 2')\n",
    "# plot_confusion_matrix(y_test1, y_pred3, 'Confusion matrix for model 3')\n",
    "# plot_confusion_matrix(y_test2, y_pred4, 'Confusion matrix for model 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 - any-label - sans scaler :\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.63      0.55      0.58     11942\n",
    "           1       0.75      0.81      0.78     20161\n",
    "\n",
    "    accuracy                           0.71     32103\n",
    "   macro avg       0.69      0.68      0.68     32103\n",
    "weighted avg       0.70      0.71      0.71     32103\n",
    "\n",
    "0.7099648007974333\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_1.png)\n",
    "\n",
    "Model 2 - end-label - sans scaler\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.99      0.96     28593\n",
    "           1       0.80      0.36      0.50      3510\n",
    "\n",
    "    accuracy                           0.92     32103\n",
    "   macro avg       0.86      0.67      0.73     32103\n",
    "weighted avg       0.91      0.92      0.91     32103\n",
    "\n",
    "0.9199451764632589\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_2.png)\n",
    "\n",
    "Model 3 - any-label - avec scaler\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.72      0.64      0.68     11942\n",
    "           1       0.80      0.85      0.82     20161\n",
    "\n",
    "    accuracy                           0.77     32103\n",
    "   macro avg       0.76      0.75      0.75     32103\n",
    "weighted avg       0.77      0.77      0.77     32103\n",
    "\n",
    "0.7724511727875899\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_3.png)\n",
    "\n",
    "Model 4 - end-label - avec scaler\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.98      0.96     28593\n",
    "           1       0.76      0.59      0.67      3510\n",
    "\n",
    "    accuracy                           0.94     32103\n",
    "   macro avg       0.86      0.78      0.81     32103\n",
    "weighted avg       0.93      0.94      0.93     32103\n",
    "\n",
    "0.9351150982774196\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_4.png)\n",
    "\n",
    "On remarque qu'en utilisant le scaler, on a de meilleurs résultats et surtout un meilleur recall pour la classe minoritaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on veut maintenant équilibrer les classes pour voir si ça améliore les résultats\n",
    "\n",
    "def balance_classes(df):\n",
    "    \"\"\"\n",
    "    Équilibre les classes en prenant un nombre égal d'exemples pour chaque classe.\n",
    "    \"\"\"\n",
    "    class_0 = df[df['phrase_end'] == 0]\n",
    "    class_1 = df[df['phrase_end'] == 1]\n",
    "\n",
    "    min_length = min(len(class_0), len(class_1))\n",
    "\n",
    "    balanced = pd.concat([class_0.sample(min_length, random_state=42), class_1.sample(min_length, random_state=42)])\n",
    "    \n",
    "    # on doit reset les index pour éviter les NaN lorsque l'on attribue les valeurs à y\n",
    "    balanced = balanced.reset_index(drop=True)\n",
    "    return balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On s'est rendu compte que la classe majoritaire biasait les résultats. On va donc essayer de rééquilibrer les classes\n",
    "\n",
    "nouveaux modèles avec les classes équilibrées sur les deux types d'étiquetage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_df1 = balance_classes(transformed_sub_seqs_df1)\n",
    "# balanced_df2 = balance_classes(transformed_sub_seqs_df2)\n",
    "\n",
    "# print(balanced_df1['phrase_end'].value_counts())\n",
    "# print(balanced_df2['phrase_end'].value_counts())\n",
    "\n",
    "\n",
    "# balanced_df_flattened1 = flatten_dataframe(balanced_df1.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened1['phrase_end'] = balanced_df1['phrase_end']\n",
    "\n",
    "# balanced_df_flattened2 = flatten_dataframe(balanced_df2.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened2['phrase_end'] = balanced_df2['phrase_end']\n",
    "\n",
    "\n",
    "# X1 = balanced_df_flattened1.drop(columns=['phrase_end'])\n",
    "# y1 = balanced_df_flattened1['phrase_end']\n",
    "\n",
    "# X2 = balanced_df_flattened2.drop(columns=['phrase_end'])\n",
    "# y2 = balanced_df_flattened2['phrase_end']\n",
    "\n",
    "# X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# pipeline1 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "\n",
    "# pipeline1.fit(X_train1, y_train1)\n",
    "# y_pred5 = pipeline1.predict(X_test1)\n",
    "# print(\"Model 5\")\n",
    "# print(classification_report(y_test1, y_pred5))\n",
    "# print(pipeline1.score(X_test1, y_test1))\n",
    "\n",
    "# pipeline2 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "\n",
    "# pipeline2.fit(X_train2, y_train2)\n",
    "# y_pred6 = pipeline2.predict(X_test2)\n",
    "# print(\"Model 6\")\n",
    "# print(classification_report(y_test2, y_pred6))\n",
    "# print(pipeline2.score(X_test2, y_test2))\n",
    "\n",
    "# plot_confusion_matrix(y_test1, y_pred5, 'Confusion matrix for model 5')\n",
    "# plot_confusion_matrix(y_test2, y_pred6, 'Confusion matrix for model 6')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5 - any-label - avec scaler - balanced\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.75      0.76      0.75     12008\n",
    "           1       0.75      0.74      0.75     11935\n",
    "\n",
    "    accuracy                           0.75     23943\n",
    "   macro avg       0.75      0.75      0.75     23943\n",
    "weighted avg       0.75      0.75      0.75     23943\n",
    "\n",
    "0.7514513636553481\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_5.png)\n",
    "\n",
    "Model 6 - end-label - avec scaler - balanced\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.86      0.87      3579\n",
    "           1       0.86      0.87      0.87      3587\n",
    "\n",
    "    accuracy                           0.87      7166\n",
    "   macro avg       0.87      0.87      0.87      7166\n",
    "weighted avg       0.87      0.87      0.87      7166\n",
    "\n",
    "0.8684063633826402\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_6.png)\n",
    "\n",
    "résultats plus intéressants avec le balanced, on obtient un meilleur f1-score pour les deux classes. Cependant, le score global est moins bon que si on ne balance pas les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nouveau gridsearch pour tester mais rien de concluant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# balanced_df2 = balance_classes(transformed_sub_seqs_df2)\n",
    "\n",
    "# balanced_df_flattened2 = flatten_dataframe(balanced_df2.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened2['phrase_end'] = balanced_df2['phrase_end']\n",
    "\n",
    "# X2 = balanced_df_flattened2.drop(columns=['phrase_end'])\n",
    "# y2 = balanced_df_flattened2['phrase_end']\n",
    "\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# pipeline1 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "# param_grid = {\n",
    "#     'mlp__activation': ['relu', 'tanh'],\n",
    "#     'mlp__solver': ['sgd', 'adam'],\n",
    "#     'mlp__alpha': [0.0001, 0.001, 0.01],\n",
    "#     'mlp__learning_rate': ['constant', 'adaptive'],\n",
    "#     'mlp__max_iter': [200, 300, 400]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline1, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_best = best_model.predict(X_test2)\n",
    "# print(classification_report(y_test2, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_best = best_model.predict(X_test2)\n",
    "# print(classification_report(y_test2, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouveau model avec etiqutage hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant on ne va considérer comme des fins de phrase que les séquences qui ont une fin de phrase parmi les 3 dernières notes de la séquence\n",
    "# transformed_sub_seqs_df3 = transformed_sub_seqs_df.copy()\n",
    "# transformed_sub_seqs_df3 = transform_target_hybrid(transformed_sub_seqs_df3, 3)\n",
    "\n",
    "# print(transformed_sub_seqs_df1['phrase_end'].value_counts())\n",
    "# print(transformed_sub_seqs_df2['phrase_end'].value_counts())\n",
    "# print(transformed_sub_seqs_df3['phrase_end'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_df3 = balance_classes(transformed_sub_seqs_df3)\n",
    "# balanced_df_flattened3 = flatten_dataframe(balanced_df3.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened3['phrase_end'] = balanced_df3['phrase_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X3 = balanced_df_flattened3.drop(columns=['phrase_end'])\n",
    "# y3 = balanced_df_flattened3['phrase_end']\n",
    "\n",
    "# X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=42)\n",
    "\n",
    "# pipeline3 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "\n",
    "# pipeline3.fit(X_train3, y_train3)\n",
    "# y_pred7 = pipeline3.predict(X_test3)\n",
    "# print(\"Model 7\")\n",
    "# print(classification_report(y_test3, y_pred7))\n",
    "# print(pipeline3.score(X_test3, y_test3))\n",
    "\n",
    "# plot_confusion_matrix(y_test3, y_pred7, 'Confusion matrix for model 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform cross-validation\n",
    "# cv_scores = cross_val_score(pipeline3, X3, y3, cv=5, scoring='accuracy')\n",
    "\n",
    "# print(\"Cross-validation scores:\", cv_scores)\n",
    "# print(\"Mean cross-validation score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On va maintenant tester plusieurs longueurs de sous séquences et plusieurs étiquetages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [4, 5, 6, 7, 8, 10]\n",
    "ends = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# res = []\n",
    "\n",
    "# for length in lengths:\n",
    "#     for end in ends:\n",
    "\n",
    "#         test = f'length={length}, end={end}'\n",
    "#         # print(f\"Training with {test}\")\n",
    "\n",
    "#         # print(\"Generating subsequences\")\n",
    "#         sub_seqs_df = generate_subsequences(new_df, length=length)\n",
    "#         # print(\"Transforming features\")\n",
    "#         transformed_sub_seqs_df = transform_features(sub_seqs_df)\n",
    "#         # print(\"Transforming target\")\n",
    "#         transformed_sub_seqs_df = transform_target_hybrid(transformed_sub_seqs_df, end)\n",
    "#         # print(\"Balancing classes\")\n",
    "#         balanced_df = balance_classes(transformed_sub_seqs_df)\n",
    "#         # print(\"Flattening dataframe\")\n",
    "#         balanced_df_flattened = flatten_dataframe(balanced_df.drop(columns=['phrase_end']))\n",
    "#         balanced_df_flattened['phrase_end'] = balanced_df['phrase_end']\n",
    "\n",
    "#         X = balanced_df_flattened.drop(columns=['phrase_end'])\n",
    "#         y = balanced_df_flattened['phrase_end']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#         pipeline = Pipeline([\n",
    "#             ('scaler', StandardScaler()),\n",
    "#             ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "#         ])\n",
    "\n",
    "#         # i want classification report and confusion matrix\n",
    "\n",
    "#         pipeline.fit(X_train, y_train)\n",
    "#         y_pred = pipeline.predict(X_test)\n",
    "#         print(f\"Model {test}\")\n",
    "#         print(\"shape : \", balanced_df_flattened.shape)\n",
    "#         classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "#         score = pipeline.score(X_test, y_test)\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "#         print(\"score : \",score)\n",
    "#         res.append({\n",
    "#             'model': test,\n",
    "#             'classification_report': classification_rep,\n",
    "#             'score': score,\n",
    "#             'length': length,\n",
    "#             'end': end,\n",
    "#             'shape': balanced_df_flattened.shape\n",
    "\n",
    "#         })\n",
    "\n",
    "#         plot_confusion_matrix(y_test, y_pred, f'Confusion matrix for model {test}', display=False)\n",
    "\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voir matrice de confusion pour chaque modèle\n",
    "\n",
    "```\n",
    "Model length=4, end=1\n",
    "shape :  (44182, 53)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.87      0.86      6652\n",
    "           1       0.86      0.85      0.86      6603\n",
    "\n",
    "    accuracy                           0.86     13255\n",
    "   macro avg       0.86      0.86      0.86     13255\n",
    "weighted avg       0.86      0.86      0.86     13255\n",
    "\n",
    "score :  0.8575631837042625\n",
    "Model length=4, end=2\n",
    "shape :  (77026, 53)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.85      0.84     11535\n",
    "           1       0.84      0.83      0.83     11573\n",
    "\n",
    "    accuracy                           0.84     23108\n",
    "   macro avg       0.84      0.84      0.84     23108\n",
    "weighted avg       0.84      0.84      0.84     23108\n",
    "\n",
    "score :  0.8365068374588887\n",
    "Model length=4, end=3\n",
    "shape :  (111660, 53)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.82      0.81     16811\n",
    "           1       0.81      0.80      0.80     16687\n",
    "\n",
    "    accuracy                           0.81     33498\n",
    "   macro avg       0.81      0.81      0.81     33498\n",
    "weighted avg       0.81      0.81      0.81     33498\n",
    "\n",
    "score :  0.8063167950325393\n",
    "Model length=4, end=4\n",
    "shape :  (144434, 53)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.78      0.80      0.79     21622\n",
    "           1       0.79      0.77      0.78     21709\n",
    "\n",
    "    accuracy                           0.79     43331\n",
    "   macro avg       0.79      0.79      0.79     43331\n",
    "weighted avg       0.79      0.79      0.79     43331\n",
    "\n",
    "score :  0.7856269183725277\n",
    "Model length=5, end=1\n",
    "shape :  (32822, 66)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.87      0.86      4989\n",
    "           1       0.86      0.85      0.86      4858\n",
    "\n",
    "    accuracy                           0.86      9847\n",
    "   macro avg       0.86      0.86      0.86      9847\n",
    "weighted avg       0.86      0.86      0.86      9847\n",
    "\n",
    "score :  0.8587387021427846\n",
    "Model length=5, end=2\n",
    "shape :  (60044, 66)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.84      0.84      8948\n",
    "           1       0.84      0.83      0.84      9066\n",
    "\n",
    "    accuracy                           0.84     18014\n",
    "   macro avg       0.84      0.84      0.84     18014\n",
    "weighted avg       0.84      0.84      0.84     18014\n",
    "\n",
    "score :  0.8359609192850006\n",
    "Model length=5, end=3\n",
    "shape :  (88768, 66)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.83      0.81     13323\n",
    "           1       0.82      0.79      0.81     13308\n",
    "\n",
    "    accuracy                           0.81     26631\n",
    "   macro avg       0.81      0.81      0.81     26631\n",
    "weighted avg       0.81      0.81      0.81     26631\n",
    "\n",
    "score :  0.8103713717096617\n",
    "Model length=5, end=4\n",
    "shape :  (115642, 66)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.78      0.80      0.79     17420\n",
    "           1       0.79      0.78      0.79     17273\n",
    "\n",
    "    accuracy                           0.79     34693\n",
    "   macro avg       0.79      0.79      0.79     34693\n",
    "weighted avg       0.79      0.79      0.79     34693\n",
    "\n",
    "score :  0.7890064278096446\n",
    "Model length=6, end=1\n",
    "shape :  (27148, 79)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.87      0.86      4054\n",
    "           1       0.87      0.84      0.86      4091\n",
    "\n",
    "    accuracy                           0.86      8145\n",
    "   macro avg       0.86      0.86      0.86      8145\n",
    "weighted avg       0.86      0.86      0.86      8145\n",
    "\n",
    "score :  0.8577041129527317\n",
    "Model length=6, end=2\n",
    "shape :  (48788, 79)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.85      0.84      7280\n",
    "           1       0.85      0.83      0.84      7357\n",
    "\n",
    "    accuracy                           0.84     14637\n",
    "   macro avg       0.84      0.84      0.84     14637\n",
    "weighted avg       0.84      0.84      0.84     14637\n",
    "\n",
    "score :  0.8370567739290838\n",
    "Model length=6, end=3\n",
    "shape :  (72880, 79)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.83      0.82     10944\n",
    "           1       0.83      0.81      0.82     10920\n",
    "\n",
    "    accuracy                           0.82     21864\n",
    "   macro avg       0.82      0.82      0.82     21864\n",
    "weighted avg       0.82      0.82      0.82     21864\n",
    "\n",
    "score :  0.8188346139773143\n",
    "Model length=6, end=4\n",
    "shape :  (95522, 79)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.81      0.80     14370\n",
    "           1       0.80      0.79      0.80     14287\n",
    "\n",
    "    accuracy                           0.80     28657\n",
    "   macro avg       0.80      0.80      0.80     28657\n",
    "weighted avg       0.80      0.80      0.80     28657\n",
    "\n",
    "score :  0.7990717800188436\n",
    "Model length=7, end=1\n",
    "shape :  (22800, 92)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.87      0.86      3441\n",
    "           1       0.87      0.85      0.86      3399\n",
    "\n",
    "    accuracy                           0.86      6840\n",
    "   macro avg       0.86      0.86      0.86      6840\n",
    "weighted avg       0.86      0.86      0.86      6840\n",
    "\n",
    "score :  0.8625730994152047\n",
    "Model length=7, end=2\n",
    "shape :  (41654, 92)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.85      0.84      6293\n",
    "           1       0.84      0.83      0.84      6204\n",
    "\n",
    "    accuracy                           0.84     12497\n",
    "   macro avg       0.84      0.84      0.84     12497\n",
    "weighted avg       0.84      0.84      0.84     12497\n",
    "\n",
    "score :  0.8399615907817877\n",
    "Model length=7, end=3\n",
    "shape :  (60366, 92)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.82      0.82      9021\n",
    "           1       0.82      0.81      0.82      9089\n",
    "\n",
    "    accuracy                           0.82     18110\n",
    "   macro avg       0.82      0.82      0.82     18110\n",
    "weighted avg       0.82      0.82      0.82     18110\n",
    "\n",
    "score :  0.8163997791275538\n",
    "Model length=7, end=4\n",
    "shape :  (79592, 92)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.80      0.80     11945\n",
    "           1       0.80      0.80      0.80     11933\n",
    "\n",
    "    accuracy                           0.80     23878\n",
    "   macro avg       0.80      0.80      0.80     23878\n",
    "weighted avg       0.80      0.80      0.80     23878\n",
    "\n",
    "score :  0.8017840690175057\n",
    "Model length=8, end=1\n",
    "shape :  (23884, 105)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.86      0.87      3579\n",
    "           1       0.87      0.87      0.87      3587\n",
    "\n",
    "    accuracy                           0.87      7166\n",
    "   macro avg       0.87      0.87      0.87      7166\n",
    "weighted avg       0.87      0.87      0.87      7166\n",
    "\n",
    "score :  0.8678481719229696\n",
    "Model length=8, end=2\n",
    "shape :  (40552, 105)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.84      0.84      6100\n",
    "           1       0.84      0.83      0.84      6066\n",
    "\n",
    "    accuracy                           0.84     12166\n",
    "   macro avg       0.84      0.84      0.84     12166\n",
    "weighted avg       0.84      0.84      0.84     12166\n",
    "\n",
    "score :  0.838402104224889\n",
    "Model length=8, end=3\n",
    "shape :  (57606, 105)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.82      0.82      8606\n",
    "           1       0.82      0.82      0.82      8676\n",
    "\n",
    "    accuracy                           0.82     17282\n",
    "   macro avg       0.82      0.82      0.82     17282\n",
    "weighted avg       0.82      0.82      0.82     17282\n",
    "\n",
    "score :  0.8194074759865756\n",
    "Model length=8, end=4\n",
    "shape :  (72860, 105)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.80      0.80     10947\n",
    "           1       0.80      0.80      0.80     10911\n",
    "\n",
    "    accuracy                           0.80     21858\n",
    "   macro avg       0.80      0.80      0.80     21858\n",
    "weighted avg       0.80      0.80      0.80     21858\n",
    "\n",
    "score :  0.799341202305792\n",
    "Model length=10, end=1\n",
    "shape :  (17860, 131)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.87      0.86      2688\n",
    "           1       0.87      0.85      0.86      2670\n",
    "\n",
    "    accuracy                           0.86      5358\n",
    "   macro avg       0.86      0.86      0.86      5358\n",
    "weighted avg       0.86      0.86      0.86      5358\n",
    "\n",
    "score :  0.8613288540500187\n",
    "Model length=10, end=2\n",
    "shape :  (32084, 131)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.84      0.84      4864\n",
    "           1       0.84      0.83      0.83      4762\n",
    "\n",
    "    accuracy                           0.83      9626\n",
    "   macro avg       0.83      0.83      0.83      9626\n",
    "weighted avg       0.83      0.83      0.83      9626\n",
    "\n",
    "score :  0.8345107001869936\n",
    "Model length=10, end=3\n",
    "shape :  (48284, 131)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.82      0.81      7246\n",
    "           1       0.81      0.80      0.81      7240\n",
    "\n",
    "    accuracy                           0.81     14486\n",
    "   macro avg       0.81      0.81      0.81     14486\n",
    "weighted avg       0.81      0.81      0.81     14486\n",
    "\n",
    "score :  0.8093331492475494\n",
    "Model length=10, end=4\n",
    "shape :  (61734, 131)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.79      0.81      0.80      9213\n",
    "           1       0.80      0.79      0.80      9308\n",
    "\n",
    "    accuracy                           0.80     18521\n",
    "   macro avg       0.80      0.80      0.80     18521\n",
    "weighted avg       0.80      0.80      0.80     18521\n",
    "\n",
    "score :  0.7973111603045192\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in res:\n",
    "#     print(r['model'], r['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a ajouté un paramètre reverse dans la fonction generate_subsequences pour pouvoir commencer à prendre les sous séquences à la fin car chaque fin de séquences est une fin de phrase. cela permet d'avoir plus d'exemple après le balance_classes dans le cas de l'étiquetage end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_seqs_df_normal = generate_subsequences(new_df)\n",
    "# sub_seqs_df_reverse = generate_subsequences(new_df, reverse=True)\n",
    "\n",
    "# transformed_sub_seqs_df_normal = transform_features(sub_seqs_df_normal)\n",
    "# transformed_sub_seqs_df_reverse = transform_features(sub_seqs_df_reverse)\n",
    "\n",
    "# transformed_sub_seqs_df_normal = transform_target_end(transformed_sub_seqs_df_normal)\n",
    "# transformed_sub_seqs_df_reverse = transform_target_end(transformed_sub_seqs_df_reverse)\n",
    "\n",
    "# balanced_df_normal = balance_classes(transformed_sub_seqs_df_normal)\n",
    "# balanced_df_reverse = balance_classes(transformed_sub_seqs_df_reverse)\n",
    "\n",
    "# balanced_df_flattened_normal = flatten_dataframe(balanced_df_normal.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened_normal['phrase_end'] = balanced_df_normal['phrase_end']\n",
    "\n",
    "# balanced_df_flattened_reverse = flatten_dataframe(balanced_df_reverse.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened_reverse['phrase_end'] = balanced_df_reverse['phrase_end']\n",
    "\n",
    "# print(balanced_df_flattened_normal['phrase_end'].value_counts())\n",
    "# print(balanced_df_flattened_reverse['phrase_end'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_normal = balanced_df_flattened_normal.drop(columns=['phrase_end'])\n",
    "# y_normal = balanced_df_flattened_normal['phrase_end']\n",
    "\n",
    "# X_reverse = balanced_df_flattened_reverse.drop(columns=['phrase_end'])\n",
    "# y_reverse = balanced_df_flattened_reverse['phrase_end']\n",
    "\n",
    "# X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(X_normal, y_normal, test_size=0.3, random_state=42)\n",
    "# X_train_reverse, X_test_reverse, y_train_reverse, y_test_reverse = train_test_split(X_reverse, y_reverse, test_size=0.3, random_state=42)\n",
    "\n",
    "# pipeline_normal = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "\n",
    "# pipeline_reverse = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "# ])\n",
    "\n",
    "# pipeline_normal.fit(X_train_normal, y_train_normal)\n",
    "# pipeline_reverse.fit(X_train_reverse, y_train_reverse)\n",
    "\n",
    "# y_pred_normal = pipeline_normal.predict(X_test_normal)\n",
    "# y_pred_reverse = pipeline_reverse.predict(X_test_reverse)\n",
    "\n",
    "# print(\"Model normal\")\n",
    "# print(classification_report(y_test_normal, y_pred_normal))\n",
    "# print(pipeline_normal.score(X_test_normal, y_test_normal))\n",
    "\n",
    "# print(\"Model reverse\")\n",
    "# print(classification_report(y_test_reverse, y_pred_reverse))\n",
    "# print(pipeline_reverse.score(X_test_reverse, y_test_reverse))\n",
    "\n",
    "# plot_confusion_matrix(y_test_normal, y_pred_normal, 'Confusion matrix for model normal', display=True)\n",
    "# plot_confusion_matrix(y_test_reverse, y_pred_reverse, 'Confusion matrix for model reverse', display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model normal\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.86      0.86      3579\n",
    "           1       0.86      0.87      0.87      3587\n",
    "\n",
    "    accuracy                           0.87      7166\n",
    "   macro avg       0.87      0.87      0.87      7166\n",
    "weighted avg       0.87      0.87      0.87      7166\n",
    "\n",
    "0.8653363103544516\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_normal.png)\n",
    "Model reverse\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.91      0.90      6910\n",
    "           1       0.91      0.89      0.90      6833\n",
    "\n",
    "    accuracy                           0.90     13743\n",
    "   macro avg       0.90      0.90      0.90     13743\n",
    "weighted avg       0.90      0.90      0.90     13743\n",
    "\n",
    "0.900676708142327\n",
    "```\n",
    "![confusion_matrix](confusion_matrix_for_model_reverse.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [12, 14, 16, 18, 20]\n",
    "ends = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# res = []\n",
    "\n",
    "# for length in lengths:\n",
    "#     for end in ends:\n",
    "\n",
    "#         test = f'length={length}, end={end}'\n",
    "#         # print(f\"Training with {test}\")\n",
    "\n",
    "#         # print(\"Generating subsequences\")\n",
    "#         sub_seqs_df = generate_subsequences(new_df, length=length, reverse=True)\n",
    "#         # print(\"Transforming features\")\n",
    "#         transformed_sub_seqs_df = transform_features(sub_seqs_df)\n",
    "#         # print(\"Transforming target\")\n",
    "#         transformed_sub_seqs_df = transform_target_hybrid(transformed_sub_seqs_df, end)\n",
    "#         # print(\"Balancing classes\")\n",
    "#         balanced_df = balance_classes(transformed_sub_seqs_df)\n",
    "#         # print(\"Flattening dataframe\")\n",
    "#         balanced_df_flattened = flatten_dataframe(balanced_df.drop(columns=['phrase_end']))\n",
    "#         balanced_df_flattened['phrase_end'] = balanced_df['phrase_end']\n",
    "\n",
    "#         X = balanced_df_flattened.drop(columns=['phrase_end'])\n",
    "#         y = balanced_df_flattened['phrase_end']\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#         pipeline = Pipeline([\n",
    "#             ('scaler', StandardScaler()),\n",
    "#             ('mlp', MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200))\n",
    "#         ])\n",
    "\n",
    "#         # i want classification report and confusion matrix\n",
    "\n",
    "#         pipeline.fit(X_train, y_train)\n",
    "#         y_pred = pipeline.predict(X_test)\n",
    "#         print(f\"Model {test}\")\n",
    "#         print(\"shape : \", balanced_df_flattened.shape)\n",
    "#         classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "#         score = pipeline.score(X_test, y_test)\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "#         print(\"score : \",score)\n",
    "#         res.append({\n",
    "#             'model': test,\n",
    "#             'classification_report': classification_rep,\n",
    "#             'score': score,\n",
    "#             'length': length,\n",
    "#             'end': end,\n",
    "#             'shape': balanced_df_flattened.shape\n",
    "\n",
    "#         })\n",
    "\n",
    "#         # plot_confusion_matrix(y_test, y_pred, f'Confusion matrix for model {test}', display=False)\n",
    "\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nouveau test de plusieurs modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# sub_seqs_df = generate_subsequences(new_df, length=18, reverse=True)\n",
    "# transformed_sub_seqs_df = transform_features(sub_seqs_df)\n",
    "# transformed_sub_seqs_df = transform_target_hybrid(transformed_sub_seqs_df, 1) # équivalent à transform_target_end\n",
    "# balanced_df = balance_classes(transformed_sub_seqs_df)\n",
    "# balanced_df_flattened = flatten_dataframe(balanced_df.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened['phrase_end'] = balanced_df['phrase_end']\n",
    "# print(balanced_df_flattened.shape)\n",
    "\n",
    "# X = balanced_df_flattened.drop(columns=['phrase_end'])\n",
    "# y = balanced_df_flattened['phrase_end']\n",
    "\n",
    "# models = {\n",
    "#     'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "#     'SVM': SVC(),\n",
    "#     'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "#     'KNN': KNeighborsClassifier(),\n",
    "#     'MLP': MLPClassifier(activation='relu', solver='sgd', alpha=0.0001, learning_rate='constant', max_iter=200),\n",
    "#     'Naive Bayes': GaussianNB(),\n",
    "#     'Decision Tree' : DecisionTreeClassifier(),\n",
    "#     'SGD' : SGDClassifier()\n",
    "# }\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     pipeline = Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "#     scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "#     print(f\"{name}:\")\n",
    "#     print(f\"Cross-validation scores: {scores}\")\n",
    "#     print(f\"Mean cross-validation score: {scores.mean()}\")\n",
    "#     print(\"-\" * 30)\n",
    "\n",
    "# random forest semble être le meilleur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(32492, 235)\n",
    "\n",
    "Logistic Regression:\n",
    "Cross-validation scores: [0.92306509 0.92891214 0.9242844  0.92474608 0.92674669]\n",
    "Mean cross-validation score: 0.9255508778938977\n",
    "\n",
    "SVM:\n",
    "Cross-validation scores: [0.92845053 0.93537467 0.92997845 0.92951677 0.93213296]\n",
    "Mean cross-validation score: 0.9310906794335526\n",
    "\n",
    "Random Forest:\n",
    "Cross-validation scores: [0.93229728 0.94045238 0.93674977 0.92874731 0.93382579]\n",
    "Mean cross-validation score: 0.9344145044735676\n",
    "\n",
    "KNN:\n",
    "Cross-validation scores: [0.79904601 0.80150792 0.79347492 0.79870729 0.79716836]\n",
    "Mean cross-validation score: 0.7979809001560058\n",
    "\n",
    "MLP:\n",
    "Cross-validation scores: [0.92506539 0.93306663 0.92336103 0.92920899 0.92951677]\n",
    "Mean cross-validation score: 0.9280437632496057\n",
    "\n",
    "Naive Bayes:\n",
    "Cross-validation scores: [0.8052008  0.80443145 0.79285934 0.79270545 0.80440135]\n",
    "Mean cross-validation score: 0.7999196789088607\n",
    "\n",
    "Decision Tree:\n",
    "Cross-validation scores: [0.88921373 0.89152177 0.8910434  0.888735   0.88734995]\n",
    "Mean cross-validation score: 0.8895727689905273\n",
    "\n",
    "SGD:\n",
    "Cross-validation scores: [0.899523   0.91660255 0.91151123 0.91812865 0.91982148]\n",
    "Mean cross-validation score: 0.9131173861016381\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search random forest\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sub_seqs_df = generate_subsequences(new_df, length=18, reverse=True)\n",
    "# transformed_sub_seqs_df = transform_features(sub_seqs_df)\n",
    "# transformed_sub_seqs_df = transform_target_hybrid(transformed_sub_seqs_df, 1) # équivalent à transform_target_end\n",
    "# balanced_df = balance_classes(transformed_sub_seqs_df)\n",
    "# balanced_df_flattened = flatten_dataframe(balanced_df.drop(columns=['phrase_end']))\n",
    "# balanced_df_flattened['phrase_end'] = balanced_df['phrase_end']\n",
    "# print(balanced_df_flattened.shape)\n",
    "\n",
    "# X = balanced_df_flattened.drop(columns=['phrase_end'])\n",
    "# y = balanced_df_flattened['phrase_end']\n",
    "\n",
    "# param_grid = {\n",
    "#     'model__n_estimators': [100, 200, 300],\n",
    "#     'model__max_depth': [None, 5, 10],\n",
    "#     'model__min_samples_split': [2, 5, 10],\n",
    "#     'model__min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# # Create the pipeline\n",
    "# pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('model', RandomForestClassifier(random_state=42)) \n",
    "# ])\n",
    "\n",
    "# # Create the Grid Search object\n",
    "# grid_search = GridSearchCV(estimator=pipeline, \n",
    "#                           param_grid=param_grid, \n",
    "#                           cv=5, \n",
    "#                           scoring='accuracy', \n",
    "#                           n_jobs=-1, \n",
    "#                           verbose=2)\n",
    "\n",
    "# # Fit the Grid Search to the data\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Print the best parameters and score\n",
    "# print(\"Best parameters found by grid search:\", grid_search.best_params_)\n",
    "# print(\"Best accuracy score:\", grid_search.best_score_)\n",
    "\n",
    "# # Evaluate the best model on the data\n",
    "# best_model = grid_search.best_estimator_\n",
    "# scores = cross_val_score(best_model, X, y, cv=5, scoring='accuracy')\n",
    "# print(f\"Cross-validation scores with best model: {scores}\")\n",
    "# print(f\"Mean cross-validation score with best model: {scores.mean()}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters found by grid search: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}  \n",
    "Best accuracy score: 0.9345992098317941  \n",
    "Cross-validation scores with best model: [0.93122019 0.94045238 0.9382887  0.93013235 0.93290243]  \n",
    "Mean cross-validation score with best model: 0.9345992098317941  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitch =  [69, 78, 69, 78, 69, 83, 81, 80, 81, 69, 79, 78, 75, 76, 69, 78, 76, 73, 74, 69, 78, 69, 78, 69, 83, 81, 80, 81, 69, 79, 78, 75, 76, 69, 78, 76, 74, 62, 67, 69, 71, 72, 74, 76, 78, 79, 78, 76, 74, 78, 69, 69, 71, 72, 76, 71, 74, 69, 71, 74, 76, 71, 74, 69, 71, 72, 71, 69, 71, 69, 71, 67, 74, 83, 81, 83, 81, 81, 79, 78, 76, 79, 78, 76, 74, 78, 69, 69, 71, 72, 76, 71, 74, 69, 71, 72, 76, 71, 74, 69, 71, 72, 71, 69, 71, 67, 71, 74, 79, 79]\n",
      "beat =  [1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.5, 1.0, 2.0, 3.0, 1.0, 3.0, 3.5, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.5, 2.0, 1.0, 3.0, 3.5, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.5, 1.0, 2.0, 3.0, 1.0, 3.0, 3.5, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 50\n",
    "print(\"pitch = \",new_df['midipitch'][i])\n",
    "\n",
    "print(\"beat = \",new_df['beat'][i])\n",
    "new_df['phrase_end'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [50, 100, 200],         # Nombre d'arbres dans la forêt\n",
    "        'model__max_depth': [5, 10, 20, None],         # Profondeur maximale de chaque arbre\n",
    "        'model__min_samples_split': [2, 5, 10],        # Nombre minimal d'échantillons pour diviser un nœud\n",
    "        'model__min_samples_leaf': [1, 2, 5],          # Nombre minimal d'échantillons pour un nœud feuille\n",
    "        'model__max_features': ['sqrt', 'log2', None],     # Nombre de features à considérer pour trouver la meilleure division\n",
    "        'model__bootstrap': [True, False]                  # Si bootstrap est utilisé pour construire les arbres\n",
    "    },\n",
    "    'MLP': {\n",
    "        'model__hidden_layer_sizes': [(50,), (100,), (50, 50)],  # Architecture du réseau\n",
    "        'model__activation': ['tanh', 'relu'],                 # Fonction d'activation\n",
    "        'model__solver': ['adam', 'sgd'],                                     # Méthode d'optimisation\n",
    "        'model__learning_rate': ['constant', 'adaptive'],                # Stratégie d'apprentissage\n",
    "        'model__learning_rate_init': [0.001, 0.01, 0.1],                               # Taux d'apprentissage initial\n",
    "        'model__max_iter': [200, 500],                                           # Nombre maximal d'itérations\n",
    "        'model__alpha': [0.0001, 0.001, 0.01]                                     # Paramètre de régularisation L2\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model__C': [0.1, 1, 10],                # Pénalité pour erreurs (régularisation)\n",
    "        'model__kernel': ['poly', 'rbf', 'sigmoid'],  # Type de noyau\n",
    "        'model__gamma': ['scale', 'auto'], # Coefficient pour les noyaux poly/rbf/sigmoid\n",
    "        'model__degree': [3, 4],                   # Degré du polynôme pour le noyau poly\n",
    "        'model__class_weight': [None]     # Gestion du déséquilibre des classes\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model__C': [0.1, 1, 10],               # Inverse de la force de régularisation\n",
    "        'model__penalty': ['l1', 'l2', 'elasticnet'],  # Type de régularisation\n",
    "        'model__solver': ['lbfgs', 'saga'],       # Solveur pour optimisation\n",
    "        'model__class_weight': [None],            # Poids des classes\n",
    "    }\n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    'RandomForest': Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('model', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'MLP': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', MLPClassifier(max_iter=500, random_state=42))\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(probability=True, random_state=42))\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score) # Pas utile si classes déséquilibrées\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(X, y, pipeline, param_grid, scoring='accuracy'):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        refit='f1',\n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45808, 105), Balanced: True\n",
      "Testing RandomForest with sequence length 8, label 1, balanced: True\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=100; total time=   5.4s\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=100; total time=   5.4s\n",
      "Testing MLP with sequence length 8, label 1, balanced: True\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] END model__activation=relu, model__alpha=0.0001, model__hidden_layer_sizes=(100,), model__learning_rate=constant, model__learning_rate_init=0.001, model__max_iter=500, model__solver=adam; total time=  52.9s\n",
      "[CV] END model__activation=relu, model__alpha=0.0001, model__hidden_layer_sizes=(100,), model__learning_rate=constant, model__learning_rate_init=0.001, model__max_iter=500, model__solver=adam; total time= 1.0min\n",
      "Testing GradientBoosting with sequence length 8, label 1, balanced: True\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] END model__criterion=friedman_mse, model__learning_rate=0.1, model__max_depth=5, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   3.9s\n",
      "[CV] END model__criterion=friedman_mse, model__learning_rate=0.1, model__max_depth=5, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=100, model__subsample=0.8; total time=   4.0s\n",
      "Testing SVM with sequence length 8, label 1, balanced: True\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] END model__C=1, model__class_weight=None, model__degree=3, model__gamma=scale, model__kernel=rbf; total time= 4.4min\n",
      "[CV] END model__C=1, model__class_weight=None, model__degree=3, model__gamma=scale, model__kernel=rbf; total time= 4.5min\n"
     ]
    }
   ],
   "source": [
    "seq_lengths = [8, 12, 16, 20]\n",
    "labels = [1]\n",
    "balance_options = [True]  # Toggle for balancing\n",
    "\n",
    "results = []\n",
    "\n",
    "for seq_length in seq_lengths:\n",
    "    for label in labels:\n",
    "        for balance in balance_options:\n",
    "            sub_seqs_df = generate_subsequences(new_df, length=seq_length, reverse=True)\n",
    "            transformed_sub_seqs_df = transform_features(sub_seqs_df)\n",
    "            transformed_sub_seqs_df = transform_target_hybrid(transformed_sub_seqs_df, label)\n",
    "\n",
    "            if balance:\n",
    "                balanced_df = balance_classes(transformed_sub_seqs_df)\n",
    "            else:\n",
    "                balanced_df = transformed_sub_seqs_df\n",
    "\n",
    "            balanced_df_flattened = flatten_dataframe(balanced_df.drop(columns=['phrase_end']))\n",
    "            balanced_df_flattened['phrase_end'] = balanced_df['phrase_end']\n",
    "\n",
    "            X = balanced_df_flattened.drop(columns=['phrase_end'])\n",
    "            y = balanced_df_flattened['phrase_end']\n",
    "\n",
    "            for pipeline_name, pipeline in pipelines.items():\n",
    "                print(f\"Testing {pipeline_name} with sequence length {seq_length}, label {label}, balanced: {balance}\")\n",
    "\n",
    "                best_model, best_params, best_score = perform_grid_search(\n",
    "                    X, y,\n",
    "                    pipeline,\n",
    "                    param_grids[pipeline_name],\n",
    "                    scoring=scorers\n",
    "                )\n",
    "\n",
    "                results.append({\n",
    "                    'Model': pipeline_name,\n",
    "                    'Seq_Length': seq_length,\n",
    "                    'Label': label,\n",
    "                    'Balanced': balance,\n",
    "                    'Shape': balanced_df_flattened.shape,\n",
    "                    'Best_Params': best_params,\n",
    "                    'Best_Score': best_score\n",
    "                })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by='Best_Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
